{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 聚类\n",
    "# 多个高斯分布，使用最大似然对每个高斯分布分别求参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEBCAYAAAB2RW6SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VNXdx/HPyb5DWBISlrBvISRA2GQVUFHqVq17XapWbWvV1vaxttXW1to+ta1dH6t1qXWXui+ggIIgS9gCISwJEMjGmoQkZM+c548zAwESkkxm7p0Zfu/Xa14js9z7k4TvnDn3LEprjRBCiMAVZHcBQgghvEuCXgghApwEvRBCBDgJeiGECHAS9EIIEeAk6IUQIsBJ0AshRICToBdCiAAnQS+EEAEuxO4CAHr16qUHDhxodxlCCOFXNmzYcERr3bu91/lE0A8cOJD169fbXYYQQvgVpdS+jrxOum6EECLASdALIUSAk6AXQogAJ0EvhBABToJeCCECnAS9EEIEOAl6IYQIcBL0QgjPKCmB556Dpia7KxGnkaAXQnRdUxNcdRXccQdcfDGUl9tdkWhBgl4I0XW//jWsWQN33gnLl8ODD9pdkWhBgl4I0TVVVfDEE+jrb6D40Wfghhvg7behocHuyoSTBL0QomuWLYOGBp7lTvr1gz/suxoqKszjwidI0AshumbxYhxRMTzw1nmkp8MvVl1ATUgsLFxod2XCSYJeCOE+reGTT1gbO5eQqDAWL4Zb7wrnPcdlON5+Bxob7a5QIEEvhOiKvDwoKODfB+fzgx9AYiLceCO867iUoPIy2LLF7goFEvRCiK5YvNjccRELFpiHJk+GwwMyzR82brSpMNGSBL0Qwn1ZWZRHJVPebRDjxpmHlILpNw+mgm7UrpKg9wUS9EII923ZQjbpzJ4NwcEnH77gQsVGxlO3WoLeF0jQCyHc09CAzs1lTc1Y5sw59alx42AT44ndnS0XZH2ABL0Qwj07d6IaG8km/Yygj4mBg33HE9JcDzt22FOfOEGCXgjhnuxsAPbGjCU19cyngzLHA6DXb7CyKtEKCXohhHu2bKFBhRE+dgRKnfl0v/OHUU001V9KP73dJOiFEG7R2dlsD0pl5JiQVp/PnBxMLqOp3ZBrcWXidBL0Qgi3ODZvYWNzOmPGtP58ejrkq2GEFeRZW5g4gwS9EKLzysoIPnSAHMa0GfSRkVDRaxhxlYVQV2dtfeIUEvRCiM7Lzwcgj2FtBj1A48BhBKFh926LChOtkaAXQnSeM7jL4ofSu3fbLwsZPRyA5h3SfWMnCXohROfl5+NAEZ02+Kwvi580DIDydRL0dmr9crkQQpyFzsunRPVlRHrEWV83MKM7h+lFbbYEvZ2kRS+E6LTG7fnk6aGMGHH21w0fbvrx1W4JejtJ0AshOm93PvkMZciQs7+sZ0/YFzaMmFIJejtJ0AshOqeykrDyQ+QzlMFn76JHKahMGEb88WKoqbGmPnEGCXohROc4R9zsZigpKe2/vGnQsFPeJ6wnQS+E6BznGPqqxKGEh7f/8qhR5tOgbtc+b1YlzkKCXgjROc6WefCwdvptnHqON0F/dON+r5Ukzk6CXgjROXv2cCSoN0nDYzv08j7pidQTRu0OadHbRYJeCNEpzXv2sccxsN0LsS4pg4IopD+OAmnR20WCXgjRKU1797OfAR0O+oQEKAoaQNgBadHbRYJeCNFxWhNStK9TQa8UHI1JIbZcWvR2kaAXQnTc0aMEN9Syj5QOBz1ATa8BxNeWQEOD92oTbZKgF0J03H7TKj8UPoBevTr+tua+KWa54uJiLxUmzkaCXgjRcftMP3tj0oBW94ltS+iQAQDUy1h6W0jQCyE6ztmiVwM7MCW2hejR5vVlm6Wf3g4S9EKIjtu3j1oi6Ta4Z6fe1jOjPwDHc6VFbwcJeiFEhzkK9lNACv0HdKLfBkgZEcEBEmnaIy16O0jQCyE6rHG3GUPfv3/n3pecDIX0J7hEgt4OEvRCiA5ThfvcCvqQECiP7EtEWYl3ChNnJUEvhOiY2lrCyg+xjxT69ev82493TyauWoLeDhL0QoiOcY6BL6R/p1v0AI29kunWVAZ1dR4uTLRHgl50jNbwl7/AjBlwxRWwcqXdFQmrOYP+WHRfYmI6/3ad3Nfcl5R6sirRARL0on0OB9x+O9x3H1RVwbp1cMEF8OmndlcmrFTi7HZJTnbr7WEDzfuqdkr3jdUk6EX7Xn4ZXngBHn4YNm2C7GwYMcK07AsL7a5OWMXZog8d2Nett0cNM0Ffvk2C3moS9OLsqqrgoYdg0iT41a/MUoS9e8N775mW/s9+ZneFwirFxVQTTc9BcW69vUeqCfrjeRL0VpOgF2f35JNQWgp//jMEtfh1SUmB+++Hl16CjRvtq09YpqmwhBKSOz1ZyiVxVA/qCaNxnwS91SToRduamuCZZ+BrX4MpU858/ic/gfh4+N3vrK9NWK6xoJhi+ro1tBIgKVlRQjKUStBbTYJetG3RIjhwAO64o/Xnu3WDm2+Gd9+FI0esrU1YThWboE9Kcu/9oaFwODSZsCMS9FaToBdte/55sw/cJZe0/ZrbbzebSbz8snV1CetpTegR03Xj5qAbACqjk4k+JkFvNQl60bojR+CDD0yLPTS07delpcHkyfDss2asvQhMR48S3NTQpRY9QG2PZLPTlLCUBL1o3ccfmz76665r/7Xf+hbk5sLWrd6vS9jDObTyYEhfevRw/zDNCcnEOiqhutpDhYmOkKAXrfvoI+jTB8aNA2DpUnjkEfjtb6G+/rTXXn65GXb53nvW1yms4Qz6hl59O7Wz1OmC+pl+n9o9MjvWShL04kyNjbB4sembDwriH/+AefPg8cfNQJsZM05OkgQgMRGmTjUXZUVgcv7AdVIXOuiBiMHm/Ue3SveNlSToxZm++gqOHYMFC/jkE7j3Xrj0UjN36u23TS/Nt7992nsuv9yMp98v640HJGeLPiylCx30QOwIE/SVOyTorSRBL8708ccQGkrT7Hl8//swahS89hpERcGVV8Ivf2l6dj76qMV7rrjC3Ev3TWAqLuaQSqB337AuHabHGBP09Xsl6K0kQS/OtHQpnHceby6KIz/frHwQHX3y6XvvNUvdPPAANDc7Hxw+3NwWLbKlZOFdzYUlFOvkLo24AegzPI7jRNFcKEFvJQl6carKSti0CT1zFo8/DqmpplempbAweOwxyMuDJUtaPHHBBbB8uRlXLwJK034zWaorY+gB4ropSlUywQeLPVOY6BAJenGq1avB4SA7bga5uWY9s6BWfksuvxx69oTnnmvx4Lx5cPw4rF1rWbnCGqqka7NiTxxHwdFw2VLQahL04lQrVkBICM/lTiU6Gr7+9dZfFh4ON9102uoHs2ebT4VTmvnC7zU0EFZxmBK63nUDUBWbTGyVBL2VJOjFqb78Esf4Cbz6XjSXXWYuwLbl9tvNSMxXX3U+0L27Wc5Ygj6wlJox757ougGo65FMz/oSmUltIQl6cVJdHaxdy77+Mygra39SbFoajBlz2vD5efNM101lpVdLFRZyDq08ENSXnj27frjmxGQidS264ljXDyY6RIJenLR+PTQ08EHFDLp1g4suav8tCxbAl1+aYfeA6b5pbjZ9/SIwOCdLNfRKbvV6TWcF9TdfC6p3SfeNVSToxUnr1gHwr62TmT/f9MO3Z8ECsyTOZ585H5g8GYKDYdUq79UprOVs0dPXvS0ETxcxSLYUtJoEvTgpK4uGpAFsPZTIBRd07C1Tp5q9Rz780PlATAykp0vQB5LiYupVOFH9PdBvA8SNlBa91SToxUnr1rGv90SADgd9SAjMn28m0zoczgenTYM1a8yVWuH/iospVckk9+3CamYt9Eg1Q3dkdqx1JOiFcfQo7NnDl/WTGDECBgzo+Fvnz4fDhyEnx/nA9OlQUwPZ2V4pVVjLUVRCkcMzQysB+gyJpoJuOIok6K0iQS+MrCwA3iqY2OHWvMusWeZ++XLnA9OmmXvpvgkIzYWemSzlEhsLB4KSCT4kQW8VCXphZGWhlWJV/QTmzevcW1NSzDeAFSucD/Ttax6UoPd/WhNU6pnlD1oqi0gmslyC3ioS9MJYt46jvUZSRRzTp3f+7TNnmqA/MQdm2jRYuVImxfi7ykqC62o8NivW5XhsErHVsvmIVSTohbF5M1vDxjNyJG5Nipk1Cw4dgp07nQ9Mn25mVBYUeLJKYTXn0EpPdt0A1PdIktmxFpKgF1BWBkVFLC8be6J7vbNmzjT3J7pvpJ8+MLSYFdu7t+cO60hMIpwGdFm55w4q2iRBL2DLFgBW16a7HfTDhpkdBVeudD6QmgpxcS0eEH6pxazY4GDPHTa4v/l6ULlTum+sIEEvTgyDzCad885z7xBKmUmxzsm1Znbs1KnSovd3Hp4V6xI5yAR9ea4EvRUk6AVs2UJlRG+aeyYyfLj7h5k0yfTRV1Q4H5g+HbZtg3L5eu63ios5FhxPz36RHj1s3AgT9NV5EvRWkKAXkJ1NTnA6U6YqVBcmP06ebO6dQ/LhvPPMxbYTzXzhd0pKPD7iBk7Ojq0rkKC3ggT9ua6pCZ2Tw+rj6Uyc2LVDZWaa+xO5PnGi2YhEVrL0W46iYvY3e3YMPUCfYbFUE42jWILeChL057q8PFR9PdmMPRHU7ureHUaObBH0sbFmwfo1a7pcprCH9vCsWJeoKDgYlETwIQl6K0jQn+taXIidMKHrh5s0yew7cmJ49JQp5oETK54Jv9HcTNDhA14JejCzYyPKJeitIEF/rsvOpkmFUN1vFImJXT/cpElw8CAUFTkfmDLFXJ09MZNK+I2DB1EOByUke7zrBqBaZsdaRoL+XLdlC/mho0ifGOaRw40fb+43b3Y+MHWquZfuG//jpVmxLvXxSfSol6C3ggT9Oc6xOZushvQu98+7pKWZMfUngn74cNN5L0Hvf5xBX0JfEhI8f3hHnyRidDW6qtrzBxenkKA/lx09SlBJscf658FsMDV0aIugDwoy4y4l6P2Pc1ZsY+9kQkI8f/iQfjJpyioS9Ocy59IHWxh7osvFEzIyWgQ9mO6bnByoqvLcSYT3FRfTrIIJ7euF5jwQ4ZodK3vHep0E/bnMOeLmUJ90jy5YlZEBe/ZAZaXzgSlTzKibEzOphF8oLuZwSBKJyR5c5KaF2OEm6Kt2SYve29wKeqVUsFJqiFJqsvM2RCnlnd8G4T3Z2RwJSaTfBA8Mt2khI8PcO78wmKE4IN03/qa42GsjbgB6jnHuHSuzY72uw0GvlIpTSt2jlFoCVAC7gK+ct11AhVJqqfM1cd4pV3iSI3sLm5rHnghmT3Ed70T3TXy8mUklQe9XdFERexr7e2XEDUDiyHjqCKdZZsd6XbuXWJRS8cBPgbuBSGA78CawGziK+bCIB4YAk4G/AU8qpf4PeFxrLSta+SKHA3K3s1Xf7fGgT0qCXr1a6af/4AMzk6orC+oIa2iN3l9IERd5rUUfHqHYH9RHZsdaoCPX0vcCh4FfAK9rrYvO9mKlVD/gOuDbwO2YDwHhawoKCKqvJZfRXObhoFeqlQuyU6bACy+YzvshQzx7QuF5lZUE1RyniH7M8FKLHqA8PImIMgl6b+tI1809wAit9ZPthTyA1rpIa/0kMBL4TlcLFF6ybRsAeyNTGTzY84fPyDADbRobnQ9MmWLupfvGPzinNhfRz2tdNwBVMjvWEu0Gvdb6Na31iYVKlFLdO3JgrbVDa/1aV4oTXpSbC0Bw2miCvDD2KiMD6utbrHyQmmoG2ctKlv6hRdB7q+sGzN6xMjvW+9z5J75KKdXf45UIS+lt2yhWfRkyvptXju/q93eO4DQ7Tk2aJC16f+EM+mL6eWQNpLY4EpPprstx1NR57yTCraCPAlYrpca29qRz6OVdXStLeFvj5lxydCppad45/ogREB7eSj99djbU1HjnpMJziopwoGjolUxoqPdOE+ycHXt02wHvnUS4FfSTgQPAl0qpeS2fUErdBOwE/uGB2oS3OBwE7dpOLqO9FvQhIWYp+jOCvqkJNm70zkmF5xQVURGeSK9kzyx21xbX7NiybdJ9402dDnqt9SFgJvAl8JFS6mal1JVKqa3AS0ADcKNnyxQetW8fIfU1bCOVMWO8dxrXyJsTa9O79hqUfnrfV1REaXA/T+8JfgbX7FjZO9a73LoMp7WuAS4DVgIvAAsxQzVvAlK11q97rELhec4RN4d7jSbei4NfMzLgyJETiyBCQoIZWin99L6vqIj9zd4P+hN7x+6R9W68yd0lEGYCS4DzgUpAYcbYv6r1ifab8FXOETeh6aO9epqxzqs4W7e2eHDKFNOil18Tn6aLithd790RNwAJqb1pIlj2jvWyTge9UmoZ8DmQCvwA6AP8DHhUKfWsUkoWSvNxjq3bKCaZQeM6NFLWba7+/zOCvrQUCgu9em7RBdXVqIoKCr08tBIgNDyIw0GJBB2UoPcmd0J5HPAIMFhr/ZTWul5r/RvgZuftI6VUjCeLFJ5VvzmXbXhvxI1LfDz069dicTOQHaf8gbOvzdtj6F3KwpNk71gvcyfoB2mtH9daH2/5oNb6ZWABMBVY4YnihBc4HITm5ZLLaK9eiHVJSzutRT92LERESND7shaTpbzdRw9QHZNEjMyO9Sp3Rt1UnOW5JcAswDs7FYiuc4642a5SGTXK+6dLS4Pt21sshRAaCpmZEvS+zKJZsS51MjvW6zzen661zgamePq4wkOcF2Ir+40mMtL7p0tLMyG/a1eLB6dMgQ0bzBoJwvc4g/5AUF+PbkjTFkdCEj0dh2mqa/L+yc5R7Qa9Uiqlswd1LX7mznuFlzmHVoZleHfEjUurI2+mToWGBti0yZIaRCcVFVEV3ov4pAiCLdhOKLhfEkFojmw76P2TnaM60qLPU0o9p5Tq8K6iSqnxSqnnMRuSCB/StCWXEpIYPMGa1aNHjjSzZE+5IHveeeZ+5UpLahCdVFTEwTBr+udBZsdaoSPr0V8I/BbIUkrtBhYD64A9gGtTEdfGIxOdrx8KbAAu8nTBomvqN26zZMSNS1iYWffmlBZ9nz4wfDgsXw4PPmhNIaLjioos658HiBluTiR7x3pPu0Gvtf4CmKKUmgvcCdwGfBc4fcaLAmqBD4DvaK2XerZU0WUOB2F7tpPL7VxswYgbl7S0VlY9mDUL3nwTmpuxpH9AdFxREXsbplgW9Cdmx+6VoPeWjrToAXAG91KlVAiQidlYxHWp5jBmi8ENWmu5ouKr9u8ntP44eaGpfM/CTZ7S0uD116GyEuJcuwnPnAnPPmua+p7ey1C4r64Ojhwh36KhlQC9UhNxoGgukqD3lg4HvYszyNcopdYBfYFq2RfWTzhH3NQOHm1pI9p1QTYn52T3PLNmmfvlyyXofUmLyVLnW9SiD4kM5UhQL4Jk71ivcWcJhG5KqZeAOqAAOKKU2q+UelIp5cVNx0SXOUfcRIyzZsSNi+t6wCkXZPv3h4EDTdAL32HxGHqXsvAkIspkYTNvcWcc/V8xq1R+CTyK2TQ8G7gPyFVKXeax6oRH1W3MpZQ+DM7sYel5BwwwXTanXJAFmD3bBH1zs6X1iLOwKeirYpKIrZIWvbe4E/QXA29qredqrX+ttf6V1vpSYBQm/BcqpaZ7tErhEQ2brR1x46KU2YTkjKCfNw/Kyk7bnUTY6sQWgn0t66MHqI9PIl5mx3qNO0Efhlmi+BRa63zgcmAj8FgX6xKe5nAQsce6NW5O51rz5pTViefONfdLzvh1EnYpKqImvDvNETF09+7ipqdoTkiit+MgjfUO6056DnEn6DcC6a094VyL/iVgUleKEl5QWEhYw3EKolJJsuFKytixUFHRYhMSMOPp09Lgs8+sL0i0rqiIoxGm20Yp604b3C+JUJo4lHvEupOeQ9wJ+seAW5VSc9p4Pgaodr8k4RXOC7ENw1It/Qfs0uoFWTDdNytXQm2t5TWJVuzfT3Fwf0v75wHCB8rsWG9yJ+gXAo3AIqXUP5VS5ymlIpRSoUqp2cADwL88WaToOp1jgj4q09oRNy6u7qJW++nr62U5BF9RUMDu5kGW9s/Dyb1jK3dK0HuDO0H/NpCH2QT8TswF2OOY4ZZLgRJgmVLKgnXvREcdX7eNEpIYMtHaETcurk1Izgj6WbMgPBw+/tiWukQLlZVQVkZuzUDLW/TxqeaE9XuK23mlcIc769HfqbWeDMQCI4BrgccxSx/sw+xA9RlwQCl1UCm1TCn1Fw/WLNzQlJ1DDmNsuRDrMnZsK0EfHQ1z5sAHH8g+snbbtw+AXY3WB33PNHNCR6EEvTe4vR69NvK01gu11o9ora/QWg8GugEzge8B7wARwC2eKVe4pbmZ6H25tgf9GZuQuFx6KezeDTt22FKXcCooMHdYH/RBkeEcDkog5KAEvTd0egmE9mitq4BVzpvwBXv3EtpYy4EeqXTrZl8Zrk1Idu7k1A+cBQvM/YcfYsm2V6J1LYLe6j56gCMR/YgsK7L+xOcAj+8wJXyQc8RN8ygbm/OcHHlzRvfNgAGQnm66b4R9CgpoCoviCL0sb9EDVMb1o3u1BL03SNCfA5o25wAQN8WeETcurk1Izgh6gMsvNyNvSmXUhW0KCqjoPhBQtgR9Xc9+9K6XoPcGCfpzQNWaHPYykBGZsbbWERZmwr7VoL/2WnMx9q23LK9LOBUUcDBqIN26mWvkVmtO6kcPXUZ9eY31Jw9wEvTngm1mjRvXcsF2ci2FcIbRo82wnDfesLwm4VRQQGGw9RdiXYJT+gFweLNckPU0CfpA19hIbPEOtgeNYdgwu4sxQb9vHxw71sqT114LX30F+/dbXtc5zzmGPt+GoZUukUPNFeCKHOm+8TQJ+kCXl0eIo5GKfmMIDbW7mJMXZHNyWnny2mvN/csvW1aPcHKOod9aNZABA+wpIW60adHX7JKg9zSPD68UPsaZqCrN3hE3Li1H3kybdtqTQ4bA+eebLQYfegiCLG6HNDZS+sYKShauQm3dSnh5KcFN9TQGR1LdcwBNqekkXHM+w6+fgAqyYcEgb9qzB4BN5QO5uL89JfRKNy36pgIJek+TFn2Aq8naRjNB9Jw20u5SgLNsQuJy991mPPenn1pWU2N2LjvmfofKyASSvjmPce/9griCbI43hlEe0puG5iD67V3JjPd/zIibJlIYMZTl85/g2L4Ky2r0uvx8APIYaluLvueAaMqIRxVL0HuaBH2AO742h3yGMnp8hN2lAGbp2zYvyAJccQUkJMDTT3u9Fr1zF4VTryE0I5WBy55nRcwC3rnlXfKzKhjStItJVcuYWvYxEyq/oH9zAcXrS1l+24scjh7IrMUPw8AUll/6JA3VDV6v1evy8mjs1pMK4ulvU4teKTgY2o/wwxL0niZBH+BCdpo1bnxhxI1LWppZrrjVpW3CwuCOO8zkqZ07vVNAXR2VDzxK06g0uq/5hGcSfsaXrxaxoPxlrnzxcoZnxrW6lHPfCX2Y9fwtTChfyvZXN7Gz9wxmffgj9vcax47XNnmnVqvk53Os11AA21r0AOXR/Yg5JkHvaRL0gayujm6H89kTOYY+fewu5qS0NDPqpqitf8/33QcREfD4454/+YoVHB86lrinHuO/QVfzxq/zub3kV1xwfa9OrdM/6voMJh36kLU//5CYxnIG3zCZ5Vf/Fe3w04XZ8vI4EGuGZdnVogc43r0fPWsK7SsgQEnQB7IdOwjSDmoG27PZSFtc3y7a7L5JSIB77oFXXoG8PM+ctLERfvYz9OzZlBY7+PbATxmf+wp3/DSR4GD3Dzv5sQWE7cxhU+J8Zv33+6wa8S2aak9ftc3H1dVBYSEFIUOJj7dnspRLfVIKPZsPo4/LpClPkqAPYI4tZsRNaIZvjLhxaXMTkpZ+9CPTqn/wwa4vX7x3L3rmTHj8cV7Qt/LLKzbzp5wLGD68a4d16TG0BxOL3uXzGY8wPf9FNgy+mrqKOs8c3Ap794LW7GgeZmu3DUDwQFPAsRxp1XuSBH0Aq/wym3rC6DPDB2ZKtdC9u+keOGvQJybCL38J778P77zj/slefx2dkUHdxlyu5XXWfvt5XlwY4/FWa1BIEOev+CXLr/k7kw+8z/ZBl1BVUuXZk3iL81vTpqqhtnbbAESNSgHgyIZ99hYSYCToA1hD1ma2ksaYcT4wU+o0rguyZ3X//WZVy+9+F0pKOneC8nK46Sa4/nryw1MZ1ZDNoP+5lqefpktdNe2Z9cZ3WHXPy6RVrGDf8AuoPuAH2yc7h1Z+ddj+Fn18hgn6qhwJek+SoA9UWhOzaxPZZJCaancxZ0pLM/uMnLEJSUshIfDSS1BVZVa3rOlgv+1nn5kTvPEGi6f+glGHV3DrowP57W+x5FrFtH/cyIaHFjLy+Hp2jLnK94df5uWh43tQcMy+oZUuSZl9aSKYxnwJek+SoA9UxcVE1R6lJHGcrRfX2jJ27MlNSNp94WuvwYYNcOGFcOBA268tLDSt+AsvhNhYXrpnNfNXP8rd3w3h0Uc9Wn67Jj9xBatve5bMo5+SNeZWHE0OawvojPx86vrbP+IGoFefEEpUX4IKJeg9SYI+UG0y47p1eobNhbSuzU1IWnPppfD667BxI2RkwB/+YMZmam1a+4sXw623miUUFi6Ehx/mlR9u5Ja/ZnLNNfDnP1vTkj/djOdv4/P5v2Xavtf4ctIPrS+go7Zvp6y3uTJtd9ArBYciUog8IgvbeZIEfYCqXrkZB4oes31oplQLI0acZROS1lxzDaxebZYzfvBBk0hhYWY9hfnzTcDffTfs2MFXCx7ntu9EMmeO6fnxZp98e2Z/9GO+yLifWZueYsXNz9pXSFsqKqC4mMJY0783aJDN9QCV3QcQXyktek+SRc0CVPXKTZQwlLTz7N1spC2uTUjavSDbUno6LFsGmzeb0N+/H+LjzdeD2bMhMpLiYrjqKjO7c+FCCA/31v9Bx6ggxYy1T5LVdwdT/vNdtkwdzdh7Tl/NzUa5uQBsD0olNBTblihuqS4xhYTS16GpybQGRJfJ32KACt++mU1MZL5v9twAJre/+MKNN2ZkmNtp6urgyiuhuhqWLDGfAb4gOCwAhl82AAAYlUlEQVSYYetepWTEJPp87ypKM9eTNLGf3WUZzv2E19elkpJi77efE1JSCNncTE1+CVEjbR4GFCCk6yYQVVQQX76Xwh4ZdOtmdzFty8yE4uKzX1/tKK3NZNqsLLOcva+NNOo+KJ6mhe8R4aihfPaV1FfW212SkZsLUVFkHUzxiW4bgIgRZojloSzpvvEUCfpAlJ0NQEPqOJsLObvMTHO/fn3Xj/Xii+b2yCNmJKYvGnrZaLb/5D+MrlnPVzP/x+5yjG3bYNQo9hQE+UzQdxtrgv7YVgl6T5GgD0DHV5kRN3EzfbjfBhg3zuwt0tWg37bNzKmaM8cEvS+b/JvLWTHuPs7P/jNfPfS+3eXAtm00Dk/l6FHfuBALkDjJBH39jr02VxI4JOgDUOUXmyilDyNn+9CSla2IjjaDaLKy3D/G8ePwjW9AbKxZA80n+pjbMWX579gRNZ5Rv7uVfSttHEZYUQElJRxJ9J0RNwDJQyIpJpmgPbvtLiVgSNAHoOCczWwmg3G+3XMDmO6b9evdX7fs3nvNDNtXXsGnlmI+m7DYcKI/fINgmii/+AYaaprsKcR5IXZfjG8FfVAQlEYOIeqABL2nSNAHmvp6ehzIZU/cOHr2tLuY9mVmwqFDZ1mb/izeegteeAEefhjmzfN8bd7U//yh7Hzgn2RUr2LVPIun7bo4r+VsU2Y5UV8JeoDynkPodUyC3lMk6APNtm2E6CZqR/h2/7zLxInmvrP99EVFcNddMGkSli9v4CkT/3g9Xw6/nVmrn2DLH5dYX8D69dC7N1sqBhAdDb16WV9CWxr6DyGhqVTWpfcQCfoAU/uVuRAbOc0P+m0wS9mEhHSun97hMCseNDSYoZShvrc4Z4eN+/Iv7A4bReKPb+bY7iPWnjwrCzIz2VugGDTInmUi2hI8fAgAR9fLBVlPkKAPMOVLNlBJLIPmDrG7lA6JiDATWzvTon/qKVi61NwP862l9jstJiGKuudepXvzUfJm39H1TVY66vhxM4Y+M5M9e2DwYGtO21Gx6eb39/Aa6b7xBAn6ABO8YR1ZTGTCRP/50XbmguyWLfCTn5ix8rff7v3arJB2UzpfXPRbMoveY92dz1hz0s2bweHAMT6T/Hzf+8BMmGqCvjpbgt4T/CcNRPvq6uhZnM32mEkkJtpdTMdNnGj2Cdmz5+yvq6uDG2+EHj3gX//yra6Grpr7/n2s7X4hY557gJKl271/QudXqJLkTOrr8di2ip4yIKMHFXTDkS9B7wkS9IFk0yZCdBM1aZPtrqRTOjpD9uGHISfHzID1pQuHnhASFkSfT16khmiOX3EDjlovL5Gwfj0kJ7P9mFnFzNeCPjxCURg2hIgiCXpPkKAPIJVL1wEQN2+SzZV0TmqqWWXybEG/bBn86U9mBuxFF1lXm5VSpiSx+d7nGFa9mQ0X/8y7J1u3DiZMYNcu80dfC3qAo92HEF8uQe8JEvQB5Nhn6yikH2Pn+8Bas50QFmZWsmwr6CsqzCibESPgf//X0tIsN/fPl7Fo0D1MXP4ke57x0pDLkhLYtQtmzmTXLjNDOSnJO6fqiprkoSTV7W1nv0nRERL0ASRy6zrWq0l+MSP2dJMmmdF+Ta1MEr33XpNN//kPREVZX5uVlIIJnz/JruBRxHz3ZuqKj3r+JJ9/bu7nzGHXLtOa98XrHWrkSEJponyDtOq7SoI+UBw5Qq/yfIr6TiYy0u5iOm/aNDPizzlZ84S33jJj5X/+85OTqwJd75QoDv7pVbo3HSHfG0Muly0zi/Wnp7Nrl++NuHGJmzwKgNJlO2yuxP9J0AeI5hWrAGia7EO7F3XCNGfZq1adfKykxOwOOGmSuRB7LplxbwbvT32CMfnvsvNH//LswZctg9mzaWgOpqDAN/vnAfrOGQFA9XoLRiEFOAn6AHH43ZXUEU7yZZl2l+KW/v3N9n+uoNcavvUtqK01XTb+PPvVXRcvfoCVURfQ/4/3U7V+p2cOuncvFBTAnDns2WNmGftq0A8YE0cxfVE7JOi7SoI+QDhWrCSLiUyfa/MmqV0wbRqsXGlC/umnYfFiePJJ3w0ib4uODSL6zRep0ZEcuegGs+ZDV336qbmfM4edzs8OX+26CQqCwpiRxJVI101XSdAHgpoaeu/fwLbu0+nb1+5i3Dd9uumu+fxz+OEPzTDKe+6xuyp7jVuQzJLrnmNQ2UZ2fOPnXT/gm2+aT85Ro1yrFDN6dNcP6y3HkkaRXLnDuqUhApQEfQBwrM0iVDdSlznd7lK6xNVPf+edZg2c55/3zdEgVrvqpct5u/ddDH//9xx+c5n7BzpwwOzGfu21oBRbt0JKCsTFeaxUj2sePopYXUVNXrHdpfg1CfoAcPidlQAkXD7V5kq6ZswYiIw0SyE8/TQk+9d0AK8JDYW0T/9AnhqOuvmbOA65ucrlwoWmU/666wAzy3jMGA8W6gVRE0YCULxUum+6QoI+ADR++jlbSGPyxT3sLqVLsrLMxdeYGLjmGrur8S3DMqLZ8pPXiKk/Sul5V7nXX//aaybZR4+mocHszJWW5vlaPanPbDPE8tgauSDbFRL0/q6ujoS8VayNnutzS812RkUFXH+9WbCsutoMDhGnuvrX4/hrxvP03b2C8uvv6Vy/dVYWfPUV3HILYCbGNjX5fot+0NQ+HKUHOnuL3aX4NQl6P9f85VeEOeqonjzXb/uztYZvfxsKC+FvfzOPuSZvipOUgm9+cgNPRv6c+Lefp/GJJzv+5t/8xkySuusuwHTbgO+36MMjFHnR4+hWsNnuUvyaBL2fO/T6MpoIJvm6mXaX4rZ//cvMgH38cdN9nJho5vSIM/XpAyNf/wVvcA3BP/0feP319t+UkwPvvgvf/z7ExgKwdSsEB5v1g3xdeUoGA45tlTVvukCC3s85PlvKOiYx+zIfHjpxFtu2mfy54AL40Y9Mq/X8803Qy4i61n3tsiA23/ciXzIDxw03mjUi2lJfD7fdBt27m0WDnHJyTMiH+8G0CzUugwjqObLKQ5PGzkES9P7s2DH6FGWRkzDHrzYacamtNSP94uLgpZfMBBkw4+dLS81uUqJ1j/0+kl9M/JiVQTPhm9+En/4UmptPfZHWZkLC+vXwwgvQs+eJp7Zs8f1uG5cec80qfcUfS/eNuyTo/Vj9h58RrJtpmO2fC7Tfd59p0f/nP6ZLwmX+fHP/8cf21OUPQkPh3wujuTZuEW/3vNP0wWdkmK6c/fth7Vq49FL4+9/h/vvhiitOvPfwYbMKQqafrJYx/NIR1BFO3WoJendJ0PuxQ89/SBnxjLzN/8bPP/88PPssPPQQXHjhqc/16QPjx0vQt2fAAHj2pXCuOvoMz1600Oy1eP31ZhbUlCmwZAn85S/wxz+e8r6sLHPvL6uBdu8Vwq6wNKJ2bbK7FL8VYncBwk0OB92++phFIRdzxRz/+jGuXw/f+Q7Mmwe//nXrr7nkEtNILS83g0VE6772NXNt49u/v4rYly7juiFZZuPvPn3gvPNO/arktG6d6SabMMGGgt10MHkcmfv/a7qj/HV4mY2kRe+nHGuziKs7zIEJCwgLs7uajjtyBK66yoysee01M/KjNZdcYiZxLl5sbX3+6PHHYcYM+NZdoWyMOM98in79662GPJgW/ejRZmKav2hMzyTeUcaxDfl2l+KXJOj9VOmzH9JMEEm3zbe7lA5rbDTDJw8ehP/+9+wbfE+aBL17m1GB4uxCQ83qBr17w+WXm7/ftmhtWvT+0m3j0vMysxBSwSur2nmlaI0EvT/SmtAP/stKZjD3G/6x7IHW8L3vwdKl8M9/tn8hMDjYNEo//NCMzhFnl5BgPhSPHoWrr257hYR9+8y3qkn+tX88Y74xinK60/DFV3aX4pck6P2QztlGwpHtbBp+LT38I+d56il45hn4yU9OzMJv19VXm+0FpfumY8aNM6MoV640M41bm4ewdq2597cWfXRsELlxU+m1S1r07pCg90OlT71BM0H0vuvrdpfSIR9+aIZzX3VV2xdfWzN7thn6/dZbXist4Fx7LfziF/Dvf5v70y1fbvrmx461urKuqxgzjUE1uTQcKLO7FL8jQe9vtCbknTf5Qp3PJbf5/iyp1atN+EyYcOqkqI4ICYErr4QPPoCaGu/VGGgeecRsw/jYY/Dcc6c+t2wZzJzpn1szxlxo+un3vrra5kr8jwS9n3Gs30hC+S52pF3j88MOc3JgwQLo2xc++giiojp/jBtvhKoqeOcdz9cXqJQy6/lfdJFZw+yjj8zjxcWwcyfMmWNvfe4aftMkGgmh4sMv7S7F70jQ+5mSx/5FLRH0+b5vL9i+d6+ZCBUZabYpTUhw7zgzZ8KgQabvWXRcaKjp8kpPN11mS5eeXBHUX4M+aUgUmyPPo9f6RXaX4nck6P3J8ePEL3qV98O+wYIbu9tdTZv27TOToerqTMgPHOj+sYKC4NZbTVAVFHiowHNEbKz5+x8+3KyG8OqrZvJZerrdlbnv4PiLGVKVTU1+id2l+BUJej9S8dxCopsqOXrlHURE2F1N6/bsgVmzzDC/RYsgNbXrx7zlFtMd8fzzXT/WuaZnT7MSwoAB5ueRlta56yS+ptc3LwYg76/Squ8MP/6Rn2O0puZ//85OhjPvlzPsrqZVeXkm5KuqzEU/T43VTkkxff1PP22+JYjOSUiAP//ZDLdcs8a08v3VuFvGUqKSaf7wE7tL8SsS9H6iYckKkouzWDTyAYaP8L21PjZuNP3pdXUm5MeP9+zxH3jArLr4yiuePe65YsUKMwlt2DCzPs6bb9pdkXvCIxTb+s9n6N7P0A2yEUlHSdD7idIf/p5D9GbsHzo428hCH39sQj4sDL74wjt9wOefb477pz/JhiSdpbVZcmL2bDOZavJksxSFa9tGf+O49Ari9DHy/y4z6TpKgt4PNG3cQsrWj3i7773MvjjS7nJO8X//Zy70jRhhugU80SffGqXgwQfN+vVvv+2dcwSq3FwzrPKqq8xGU4sXm1b9vffC3Xe3vVyCr5r084s4Qk+q/u8sO2uJU0jQ+4HSWx6ijHj6//Z7PrNCa02NmZTzne/AxRebGZdJSd495/XXw6hR8LOfQVOTd88VSF591VyAde09EhVl5iU89JBZd2jePDh0yN4aOyM+MYz1Q65jVN57NB45Znc5fkGC3sfVfLCU/jmf8ErKw1xyo2/MkMrLg6lT4cUXzSzM996zZsnb4GCzhMKOHWaWrWhffb3Z4OVrXzv1gzg4GJ54wnwIZGWZzamWLLGvzs6KuuubRFJH7q/+a3cp/kFrbfttwoQJWrSivl6XJqTpAgboNV/U2l2Ndji0fvpprWNitO7ZU+tPPrGnhqlTte7dW+ujR60/v7955RWtQevFi9t+zaZNWo8caV73wx9qXVdnXX3uqq9z6B3Bo3R+XIb5pThHAet1BzJWWvQ+rPS+39Ln0Fb+O+uvTJ5l78D5vXvNV/y77zYX8zZuPLm3q5Vc0/vLyszOSuLs/v53M9Jm3ry2X5ORARs2mJ/tH/5glpBe5eOLRIaFK3Zd9iOGVG5m9z/komy7OvJp4O2btOjPVL9mo25Qofq/EdfrI0fsq+P4ca0fe0zrqCjTkv/nP32jAfXjH5sW6Hvv2V2J71q0yPwd/fWvHX/PBx9o3b+/ed/tt2tbf/faU3agXheqfnpb75l2l2IbOtiitz3ktQT9GRyHDuvDMSm6kL560cuHbamhudl87Xf9o//617UuKLCllFbV1mo9frzW3btrvWeP3dX4nqYmrceO1XrwYK3r6zv33qoqrR98UOvgYK27ddP68cfNY77o/blPaQ06/y8f2V2KLSTo/VVNjd4/dLauJVz/47Z1lp++oUHrf//7ZJ/tuHFaf/GF5WV0yO7dJohSU3275WmHZ54xP7/XX3f/GFu3av21r5njJCRo/cc/al1Z6bkaPaGstE7vCB6li8NSdNOxarvLsZwEvT+qrdX7Rl2om1H6j5mv6OZm60598KDWv/ud1gMHmt+KsWNNSFhZgzuWLtU6PFzrSZO0LiuzuxrfsHOn1tHRWs+a5Zmf36pVWs+ebX4v4uK0/sEPfOtb1JJHlmsNesO0e+0uxXIS9H6maX+xLkyepDXop9Kft2TkQ22t1u++q/U112gdGmp+G2bONP20vtAP31HvvmvqHznStwLIDseOaZ2ernWPHloXFnr22GvWaH3ddaZLB0z4P/ecOaedHA6t3xtyv9agt973rL3FWEyC3l84HPrA397UZWEJuopo/Zc573S6T7UzDhzQ+uWXtb7hBq1jY81vQI8eWt9/v9a5ud47r7d9/rnpr4+LM11P/vRB5SnHjmk9ZYrWISFaf/yx985TWKj1r36l9bBh5vcnLEzriy7S+m9/03rvXu+d92yqyhv1ytj5uoEQve2hf9tThA0k6H2dw6HL3/1C5w+YrTXoDUET9JuP5ng0oBobtd6yxbS67r7bdMeYlU/MOPg77jDjqxsaPHdOO+3erfX06eb/77zztF627NwJ/PXrtR4+3IT8229bc06HQ+vVq7V+4IGToQ9ap6RoffPN5jpBVpbWNTXW1FO8/ZheHTXH/Hua/YNzos++o0GvzGvtlZmZqdevX293Gd7X2MiRj9dR+u9P6b50If0rczlAIovG/5S5C++h/6CQTh9Saygvh/37zYzVXbtO3mdnn9xrNS7OLBs8dy5ccAGMG+ff65K3pbnZrFv/6KNQWgpjxsANN5hljlNTzYzQQKE1bNliFnp7+WXo08fcz55tTz07d5p1dFasMLfDh83jwcFmLaT0dLOExaBBJ299+nj29/DY4QZWZd7HJfufpjS0PyU3PEja728hrHc3z53EhyilNmitM9t9nQS9hzQ00FRZQ11ZDTWlx6jafYiafYdoyC9E79hBdOFO+h/dRIyjimaCWB8yhV3TvsXwR69nwMgoGhqgsdFMWa+qOvVWWXnyv8vKTIAdOHDy1njaaq3JyWaSTHo6TJxobsOGBWawt6W2Fl57DZ55BtauNY/FxJi/i3HjzBr3KSnm76pbN/NB2K0bRETgM+sJuTQ3Q3W1+VkXFJjb5s1ma8CdO812jXffbdYA6tHD7moNrSE/3zQ2Wt727z/1deHhZr383r3PvMXFmZ9ZdLS5uf47Jsas1xMaajaQDw09+d8hzrbSF7/6ku6/+THj6tfQSAg7ek2neth4QtJHEz9lJN1G9CE2pQcRid38+h/GORH0f7hgEZcseQAAhW715u3ngnAQQR2htL3K1mF6sZMRbCWNJcxjGXOowL11a4KCzC9zcPCpt5a/8K6gau9He64839zMiQ/Shob2F0Q7Pehb/tmTHwJan/14JztDznwuKMgEfFycufnLNxWtT/1ZNDaan0dz86n3XY0lpcxtvN7AVXohF/Apo8klklN3rnGgaCCMRkJPuTUQhuO0hQM06qx/7shrWvvzh4l38OMDP+j0/yN0POg731fgQyISu5EbnHbiL88VxadHdMvntGr9udZiHYDTXq/VqcdzEESdiqRORVEbFEVtUDTHVSxHQxIpD02gLDyJ6vCehISYf5xKwYBgSFHmz8HB5r7lrWVoh4Wd/HNr/5jbCx55/szHtDYbpFRVmZZ/y9BpaDBhozU4HKfeu/7bU84W9K6gc32Ih4SYbxtRUaZV64vfPDypudn8PFzB3/LW8sPg9J/T6T+zcscEntUTeJYnoLmZxLp9pNTuoEfzYeKay+nuKCOMekJ1IyE0EqYbCKGRUN14olGn4cR/u5z+59Ye6+ifm3oldvWvq11+3aIXQohzWUdb9P7bOSWEEKJDJOiFECLASdALIUSAk6AXQogAJ0EvhBABToJeCCECnAS9EEIEOAl6IYQIcD4xYUopdRjYZ3cdQgjhZ1K01r3be5FPBL0QQgjvka4bIYQIcBL0QggR4CTohRAiwEnQCyFEgJOgF0KIACdBL4QQAU6CXogWlFLxSqkKpdQXpz2eqJTaq5TarpTykZ1ZhegYCXohWtBalwNPArOUUrMBlFLRwEdABHCx1rrMvgqF6DyZMCXEaZRSMcAeIBeYC7wHzAJmaq032VmbEO6QFr0Qp9FaVwNPYML9M+Ai4GoJeeGvpEUvRCuUUhHAAaAb8C2t9Qs2lySE26RFL0TrfoAJeYBKOwsRoqukRS/EaZRSNwH/AR4DrgWagTSttcPWwoRwk7TohWhBKTUPeB54QWv9KPArYDRwk62FCdEF0qIXwkkplQ6sANYCl2itm5RSQcA2IBwYobVutLNGIdwhLXohAKVUf+BjoAAzwqYJwNld8xgwCLjDtgKF6AJp0QshRICTFr0QQgQ4CXohhAhwEvRCCBHgJOiFECLASdALIUSAk6AXQogAJ0EvhBABToJeCCECnAS9EEIEOAl6IYQIcP8Pcx7K7l+GfxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 混合高斯模型\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "xx = np.linspace(-20,20,200)\n",
    "\n",
    "y1= norm.pdf(xx,loc=0,scale=4)\n",
    "y2= norm.pdf(xx,loc=10,scale=1.5)\n",
    "y3= norm.pdf(xx,loc=-8,scale=2)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "ax.plot(xx,y1,'b')\n",
    "ax.plot(xx,y2,'b')\n",
    "ax.plot(xx,y3,'b')\n",
    "\n",
    "ax.plot(xx,y1+y2+y3,'r')\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "ax.set_xlabel(\"$x$\",fontsize='xx-large')\n",
    "ax.set_ylabel(\"$p(x)$\",fontsize=\"xx-large\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单化\n",
    "\n",
    "* 一元\n",
    "\n",
    "$$\\widehat{μ} = \\frac{1}{n}\\sum_{i=1}^nx_i = \\bar{x}, \\hspace{0.5cm} \\widehat{\\sigma^2} = \\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})^2$$\n",
    "\n",
    "* 多元\n",
    "\n",
    "$$\\widehat{\\mathbf{μ}} = \\frac{1}{N}\\sum_{n=1}^N\\mathbf{x_n}, \\hspace{0.5cm} \\widehat{\\mathbf{Σ}} = \\frac{1}{N}\\sum_{n=1}^N(\\mathbf{x_n-\\widehat{\\mathbf{μ}}})(\\mathbf{x_n-\\widehat{\\mathbf{μ}}})^\\mathsf{T}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：\n",
    "# 一元高斯：特征只有一个维度，i=1,...,n表示的是n个样本数据，服从一个高斯分布，二维平面中可视\n",
    "# 一元高斯的均值μ为所有样本数和的均值，方差σ^2为每个样本与均值的偏离程度的平方和的均值\n",
    "# 多元高斯：特征可能有d维，n=1,...,N表示的是N个样本数据，仍然是一个高斯分布，只是不在属于二维平面，位于超平面中\n",
    "# 多元高斯的均值μ仍然是所有样本数和的均值，方差Σ还是每个样本与均值的偏离程度与自身的点乘和的均值，只不过是在高维超平面中\n",
    "# 混合高斯：表示有多个多元高斯，每个多元高斯的特征有d维，整个高斯的样本数据有n=1,...,N个，也是再超平面中的多个高斯分布的加权叠加\n",
    "# 混合高斯的均值μk和方差Σk则有些不同，因每个高斯混合组成了整个高斯，固然每个高斯在整个高斯中都有一个权重，这个权重在概率里可以理解为后验概率，\n",
    "# 从统计的角度也可以理解为属于这个高斯对x数据的“责任”，或者说是每个高斯对数据x的贡献度，所以混合高斯的对应的每个高斯的均值为所有数据中属于\n",
    "# 该高斯的数量和Σγ(znk)xn的均值1/NkΣγ(znk)xn，方差Σk也是所有数据中属于该高斯的样本数据与均值的偏离程度与自身的点乘和的均值1/NkΣγ(znk)(xn-μk)(xn-μk)^T\n",
    "# 而先验概率πk在每次迭代的过程中也会不一样，为属于该高斯的样本数据与总样本数之比，在E步计算之后，Nk会发生变化，也就是属于每个高斯有效样本点的数量，而\n",
    "# πk=Nk/N，如何决定每个样本点应该数据哪个高斯的呢？是通过后验概率γ(znk)来判断的，我们从γ(znk)的贝叶斯公式，利用初始值(πk,μk,Σk)，就可以求得其后验概率\n",
    "# 计算出的πk=Nk/N，其实也是符合使用最大似然计算出的先验概率，符合频率等似概率的情况\n",
    "# γ(znk)，通过比较属于哪个高斯的概率最大，自然也就是判定应属于这个高斯了。我们再看下Nk=ΣNγ(znk)公式，它属于每个样本的加权平均，也就是E[znk]的期望"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$μ_1 = \\frac{\\sum_{{\\color{blue}{\\text{blue}}}\\hspace{0.1cm}i}x_i}{\\text{# of}\\hspace{0.1cm}{\\color{blue}{\\text{blue}}}\\hspace{0.1cm}\\text{points}}, \\hspace{0.5cm} \\sigma_1^2 = \\frac{\\sum_{{\\color{blue}{\\text{blue}}}\\hspace{0.1cm}i}(x_i-μ_1)^2}{\\text{# of}\\hspace{0.1cm}{\\color{blue}{\\text{blue}}}\\hspace{0.1cm}\\text{points}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：\n",
    "# 从上式中也可以看出，在所有样本数据中，通过属于某个高斯的权重来找到属于这个高斯，继而求得每个高斯的均值和方差\n",
    "# 也就是如果我们事先就知道了每个样本应该属于哪个高斯，求每个高斯的均值和方差自然就变得很简单，虽然公式中是从所有样本点中取找属于哪个高斯\n",
    "# 但是属于某个高斯的就那么多固定的数量，不是所有的样本数据，注意不要搞混了。另外，就是因为不知道每个数据应该属于哪个高斯，这里就是通过这个\n",
    "# γ(znk)来判断的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMM模型\n",
    "# 混合高斯属于多项分布和多元高斯分布的混合模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多项分布\n",
    "\n",
    "* K维向量$\\mathbf{x}$，其中一个元素$x_k = 1$，其余剩余元素等于0，且有$\\sum_{k=1}^Kx_k = 1$。\n",
    "\n",
    "* $x_k = 1$的概率是参数$μ_k$，$\\mathbf{x}$的分布是\n",
    "    $$p(\\mathbf{x|μ}) = \\prod_{k=1}^Kμ_k^{x_k}$$\n",
    "    其中$\\mathbf{μ} = \\left(μ_1,\\dots,μ_k\\right)^T$，且有$μ_k \\ge 0$和$\\sum_kμ_k = 1$\n",
    "    \n",
    "* 考虑数据集$\\mathcal{D}$中$N$个独立的观测$\\mathbf{x_1},\\dots,\\mathbf{x_N}$，似然函数有\n",
    "    $$p(\\mathcal{D}|\\mathbf{μ}) = \\prod_{n=1}^N\\prod_{k=1}^Kμ_k^{x_{nk}} = \\prod_{k=1}^Kμ_k^{(\\sum_nx_{nk})} = \\prod_{k=1}^Kμ_k^{m_k}$$\n",
    "    其中$m_k = \\sum_nx_{nk}$，可得\n",
    "    $$μ_k^{ML} = \\frac{m_k}{N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：\n",
    "# K维向量x：表示的是每个样本数据xn属于哪个分布k，使用的是0 of k方法，就是说把某个数据xn用0,1标记的方法，在某个分布下标记为1的，这个数据\n",
    "# 就属与这个分布，总共有k个这样的元素，由此我们可以计算出每个元素xn的属于某个分布的概率∏k=1Kμxkk\n",
    "# K维中有一个元素xk=1，当j≠k时，xj=0\n",
    "# k个元素只是抽象出来的概念，用于区别每个元素属于哪个分布的概率\n",
    "# 通过这种方式我们可以表达后面混合高斯中每个元素属于哪个高斯的概率，也就是可以表示成高斯分布中的先验概率πk\n",
    "# N个独立观测数据x1,...,xN：自然可以得到N个独立观测数据属于某个分布的概率的表达\n",
    "# 而最大似然，其实也就是在估计取得这一组数据最大可能的模型参数，其似然函数也就是属于某个分布的概率，也就是概率分布或概率密度函数\n",
    "# 我们要知道似然函数其实描述的是样本点的概率密度分布，每种分布都是不同的似然函数，如0-1，二项，多项，正太，beta分布等\n",
    "# 显示生活中的很多数据都是服从上述分布，所以我们需要研究它，这些分布都能表现出很好的性质，能够为我们做预测提供帮助\n",
    "# ∑nxnk：表示的是N个独立观测数据中属于各自分布k的数据数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：为什么说其中一个元素x^k=1，其余元素都是0，就是多项分布呢？\n",
    "# 解释：为1的x_k元素在每个独立样本的分布情况是不同的，每次试验只有zk=1这个元素现象\n",
    "# 换种说法，如果说zk为1的概率为μk，那为其它的元素的概率就是不同的μk以此也就是区分出了多项\n",
    "# m^k的意思是每个x^k元素在N个独立观测x1,...,xN中的个数\n",
    "# 同样使用最大似然函数求得均值\n",
    "# 多项分布也是0-1分布的自然推广"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM\n",
    "\n",
    "* 混合高斯\n",
    "    $$p(\\mathbf{x}) = \\sum_{k=1}^K\\pi_k\\mathcal{N}(\\mathbf{x}\\mid\\mathbf{μ_k,Σ_k})$$\n",
    "    其中$\\sum_{k=1}^K\\pi_k = 1$\n",
    "    \n",
    "    \n",
    "* 最大似然\n",
    "    $$p(\\mathbf{X}\\mid\\mathbf{μ,Σ,\\pi}) = \\prod_{n=1}^N \\ln \\left\\{{\\sum_{k=1}^K\\pi_k\\mathcal{N}(\\mathbf{x_n}\\mid\\mathbf{μ_k,Σ_k})}\\right\\}$$\n",
    "    \n",
    "* 对数似然\n",
    "    $$\\ln p(\\mathbf{X}\\mid\\mathbf{μ,Σ,\\pi}) = \\sum_{n=1}^N \\ln \\left\\{{\\sum_{k=1}^K\\pi_k\\mathcal{N}(\\mathbf{x_n}\\mid\\mathbf{μ_k,Σ_k})}\\right\\}$$\n",
    "    \n",
    "    \n",
    "* 潜变量$K$维向量$\\mathbf{z}$，其中一个元素$z_k = 1$，其余剩余元素等于0，且有$\\sum_{k=1}^Kz_k = 1$。同时有$p(z_k = 1) = \\pi_k$，即\n",
    "    $$p(\\mathbf{z}) = \\prod_{k=1}^K\\pi_k^{z_k}$$\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：\n",
    "# 混合高斯的概率密度：某个元素属于某个高斯的概率密度，其中πk是某属于个高斯的概率，类似多项分布中的概率μk\n",
    "# N个独立观测数据的似然函数：表示的是各自高斯中对应的数据的概率密度分布\n",
    "# 对数似然：利用对数似然很大程度上是为了方便求导，简化计算\n",
    "# 混合高斯中独立观测数据都只有数据本身的信息，并不知道哪个数据应该属于哪个高斯分布，以此来引入潜变量z，其实呢，对于每个数据它本身应该属于哪个\n",
    "# 高斯是知道的，只是没有显现出来\n",
    "# 属于哪个高斯，这就类似一个多项分布，同样可以使用0 of k方法，对数据进行0-1标记来区分出属于哪个高斯的概率，它的概率也就是πk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：使用最大似然求解参数是很难的，因为ln(a+b+c...)这种方式求导太困难了\n",
    "# 所以不能用梯度为0法来求解，只能用迭代法，这边的迭代法是在求每次的极大值，类似坐标上升法的迭代\n",
    "# 迭代的函数是Q函数，也是期望，期望函数的log是在求和里面的，涉及到求导就方便多了\n",
    "# 迭代的思想是满足期望最大的参数θ，直到函数收敛，或满足停止条件 收敛条件也就是μ值不再发生变化，和其对应的方差\n",
    "# 在聚类里面就是质心不再发生变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：其中πk为属于每个高斯的概率\n",
    "# 解释：p(zk=1)=πk zk=1这个元素在每个高斯分布中的分布情况决定了每个高斯的概率，也就是权重\n",
    "# 潜变量z表示的是每个独立观测值区别元素的值，用于观测值的类别，比如这个观测值属于哪个高斯分布\n",
    "# 潜变量反应了一种属于某个类别的概率情况，自然也就为πk，也就是通过这个zk元素和K维向量，也就是\n",
    "# K个高斯分布来表示属于每个高斯的概率情况\n",
    "# 拿一个班级的男女身高都服从高斯分布，我们拿到一个身高数据，自然要知道这个数据是来自男生或者女生高斯\n",
    "# 那比如有K个这样的数据，也就是K个高斯分布，那其概率也就是πk^xk的积\n",
    "# πk = ∑nxnk/N\n",
    "# 用zk=1来表示是属于哪个高斯分布，但是只用zk=1一个元素不足以表示整个K分布的情况，所以需要一个z变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 类似有\n",
    "\n",
    "$$p(\\mathbf{x} \\mid z_k=1) = \\mathcal{N}(\\mathbf{x}\\mid\\mathbf{μ_k,Σ_k})$$\n",
    "    条件分布$p(\\mathbf{x}\\mid\\mathbf{z}) = \\prod_{k=1}^K\\mathcal{N}(\\mathbf{x}\\mid\\mathbf{μ_k,Σ_k})^{z_k}$\n",
    "    \n",
    "* 边缘分布\n",
    "\n",
    "    $$p(\\mathbf{x}) = \\sum_{\\mathbf{z}}p(\\mathbf{x,z}) = \\sum_{\\mathbf{z}}p(\\mathbf{z})p(\\mathbf{x}\\mid\\mathbf{z}) = \\sum_{k=1}^K\\pi_k\\mathcal{N}(\\mathbf{x}\\mid\\mathbf{μ_k,Σ_k})$$\n",
    "    \n",
    "* 定义责任(贝叶斯公式)\n",
    "\n",
    "    $$\\begin{align*}\n",
    "    γ(z_k) &= p(z_k=1 \\mid \\mathbf{x}) = \\frac{p(z_k=1)p(\\mathbf{x} \\mid z_k=1)}{\\sum_{j=1}^Kp(z_j=1)p(\\mathbf{x} \\mid z_j=1)} \\\\\n",
    "    &= \\frac{\\pi_k\\mathcal{N}(\\mathbf{x}\\mid\\mathbf{μ}_k,\\mathbf{Σ}_k)}{\\sum_{j=1}^K\\pi_j\\mathcal{N}(\\mathbf{x}\\mid\\mathbf{μ}_j,\\mathbf{Σ}_j)}\n",
    "   \\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：\n",
    "# 在确定其属于那个高斯，其概率密度为N(x∣μk,Σk)\n",
    "# 类似有x的条件分布：∏Kk=1N(x∣μk,Σk)zk，不同于单独x的分布，因知道了z的情况，自然是x的在z条件下的分布\n",
    "# 而x的分布p(x)，可以通过边缘分布所有z情况的联合概率p(x,z)求得，联合概率又可以由条件概率分布得出，继而得到引入潜变量z的情况下x的分布，与\n",
    "# 单独x的分布情况相同\n",
    "# 为什么我们定义了一个“责任”的量？\n",
    "# 因为在引入隐变量z后，x的分布不再是单独分布，而是在z条件下的x的条件分布，发生了变化，进一步分析，我们要求某个数据属于某个高斯的概率，在只有\n",
    "# 单独的观测数据x的情况下是无法求得的，没有过多的信息和条件，由此我们想到了利用贝叶斯公式，转换为在知道每个高斯的概率和知道高斯概率下数据x的条件\n",
    "# 概率，继而求得x的属于某个概率，从这个贝叶斯公式也可以看出，是需要隐变量z的支持的\n",
    "# 因为贝叶斯公式，其实描述的是一个先验概率和后验概率的情况，自然这边的πk也就是先验了，γ(znk)也就是后验了，通过先验，求得后验，这是E步，再最大化\n",
    "# 似然函数使得满足取到的观测数据x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：因最大似然求解困难，尝试引入隐变量方法求解\n",
    "# p(x∣zk=1)=N(x∣μk,Σk)：表示来自哪个高斯分布，共K个高斯分布\n",
    "# p(x∣z)=∏Kk=1N(x∣μk,Σk)：以z为条件下x的条件分布概率\n",
    "# p(x)=∑zp(x,z)：边缘分布率\n",
    "# ∑zp(x,z)=∑zp(z)p(x∣z)：条件分布率\n",
    "# p(x)=∑zp(x,z)=∑zp(z)p(x∣z)=∑k=1KπkN(x∣μk,Σk)：引入隐变量，求得p(x)\n",
    "# p(x,z)：完整的数据，x为观测数据，z为隐变量表示类别\n",
    "# 定义的责任γ(zk)：类似每个高斯分布的比重\n",
    "\n",
    "# 说明：\n",
    "# 这边的p(zk=1)=πk可以理解为时先验概率，而p(zk=1∣x)=γ(zk)理解为后验概率\n",
    "# 也可以理解为每个高斯对xn的贡献度，或者说是每个高斯占整个高斯分布的比重\n",
    "# p(zk=1∣x)是知道了样本观测值的情况下，要求属于第k个高斯的概率，这个明显很难求\n",
    "# 利用贝叶斯公式，颠倒一下\n",
    "# ∑Kj=1p(zj=1)p(x∣zj=1)：很明显是所有的高斯分布1...K\n",
    "# p(x∣zk=1)：知道了它属于哪个高斯分布，求样本x的概率分布，是高斯似然函数，也就是我们引入的\n",
    "# 隐变量的意义\n",
    "# 注意区别πk和γ(zk)，一个是默认k类的概率，另一个是这个数据属于k类概率，一个先验，一个后验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM下EM算法\n",
    "\n",
    "1、给定初值$θ$\n",
    "\n",
    "2、E步：使用当前参数计算责任，即计算模型$k$对观测数据$\\mathbf{x_n}的响应度$\n",
    "\n",
    "$$γ(z_{n,k}) = \\frac{\\pi_k\\mathcal{N}(\\mathbf{x}\\mid\\mathbf{μ}_k,\\mathbf{Σ}_k)}{\\sum_{j=1}^K\\pi_j\\mathcal{N}(\\mathbf{x}\\mid\\mathbf{μ}_j,\\mathbf{Σ}_j)}$$\n",
    "\n",
    "3、M步：使用当前责任重新估计参数\n",
    "\n",
    "$$N_k = \\sum_{n=1}^Nγ(z_{n,k}) \\hspace{0.5cm} \\pi_k = \\frac{N_k}{N}$$\n",
    "\n",
    "$$\\mathbf{μ}_k = \\frac{1}{N_k}\\sum_{n=1}^Nγ(z_{n,k})\\mathbf{x_n} - 加权平均$$ \n",
    "\n",
    "$$\\mathbf{Σ}_k = \\frac{1}{N_k}\\sum_{n=1}^Nγ(z_{n,k})(\\mathbf{x_n} - \\mathbf{μ}_k)(\\mathbf{x_n} - \\mathbf{μ}_k)^T$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：\n",
    "# 1、这边给定的初始值θ，也就是为[π,μ,Σ]，由此就可以间接得到后验概率γ(通过先验概率和隐变量的关系求得)\n",
    "# 2、继而再使用最大似然估计得到新的[π,μ,Σ]，与观测数据进行比较，直到收敛满足局部最优解，得到最终的[π,μ,Σ]\n",
    "\n",
    "# 说明：\n",
    "# 定义Nk=∑n=1Nγ(zn,k)，是说在这个N个样本中，属于k个高斯分布的有效样本数\n",
    "# 再进一步理解这个Nk，我们可以认为是一个数据可以被分成k份，每份占得比重不一样，最大的哪个比重也就是应该属于的那个分布，自然也就有\n",
    "# ∑n=1Nγ(zn,k)表示成Nk了 当每个数据的单位为1是，我们可以理解成属于每个分布的样本数量Nk，而这一个数据看做是概率分布时，则是被分成\n",
    "# k个概率情况，所有属于k分类的数据累加和自然是k分类的数量，也就是说这一个数据有多少属于k分类，通过γ(zn,k)这个权重来划分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原理解释\n",
    "\n",
    "* $N$个样本$\\mathbf{X}$ = $\\{\\mathbf{x_1},\\dots,\\mathbf{x_N}\\}$，潜变量$\\mathbf{Z}$ = $\\{\\mathbf{z_1},\\dots,\\mathbf{z_N}\\}$，参数$\\mathbf{θ}$ = $\\{\\pi_1,\\dots,\\pi_k,\\mathbf{μ}_1,\\dots,\\mathbf{μ}_k,\\mathbf{Σ}_1,\\dots,\\mathbf{Σ}_k\\}$\n",
    "    $$\\begin{align*}\n",
    "\\ln p(\\mathbf{X} \\mid \\mathbf{θ}) &= \\ln \\left\\{\\sum_{\\mathbf{z}}p(\\mathbf{X,Z} \\mid \\mathbf{θ})\\right\\} \\\\\n",
    "&= \\mathcal{L}(q,\\mathbf{θ}) + KL(q\\|p)\n",
    "\\end{align*}$$\n",
    "    其中\n",
    "    $$\\mathcal{L}(q,\\mathbf{θ}) = \\sum_{\\mathbf{Z}}q(\\mathbf{Z}) \\ln \\left\\{\\frac{p(\\mathbf{X,Z} \\mid \\mathbf{θ})}{q(\\mathbf{Z})}\\right\\}$$\n",
    "    $$KL(q\\|p) = - \\sum_{\\mathbf{Z}}q(\\mathbf{Z}) \\ln \\left\\{\\frac{p(\\mathbf{Z} \\mid \\mathbf{X,θ})}{q(\\mathbf{Z})}\\right\\}$$\n",
    "    \n",
    "* 提示$\\ln p(\\mathbf{X,Z} \\mid \\mathbf{θ}) = \\ln p(\\mathbf{Z} \\mid \\mathbf{X,θ}) + \\ln p(\\mathbf{X} \\mid \\mathbf{θ})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：\n",
    "# 我们要求对数似然ln(X|θ)，等式里对数ln里面包含Σ求和，这对某个参数求导会很困难\n",
    "# 这边的一种求解方法：\n",
    "# 是引入两个分布的距离，也就是KL散度的概念，通过使得KL距离为0，来求对数似然的最小化下界泛函的方法间接求对数似然\n",
    "# 由此引入KL距离，需要找到满足条件的KL和L(q,θ)函数，使得等于对数似然，由此也就自热而然地引入了潜变量Z\n",
    "# KL散度是一个>=0的实数，我们需要在迭代的过程不断使得KL最小，也就是为0，这个过程也就满足了让对数似然最大，因KL是一个常数，是个信息熵\n",
    "# 这种KL的要求为0，会引起泛函L(q,θ)的变化，继而我们从优化对数似然，变成优化L(q,θ)，而这个函数其实是一个期望，我们称其为\n",
    "# Q函数\n",
    "# 其实这边的使得KL=0，也就是EM算法中的E步，而M步，就是优化L(q,θ)，使得对数似然不断变大，L(q,θ)变大的时候，对数似然也在随着变大\n",
    "# 对数似然增加的量为L(q,θ)增加的量和变化后KL的距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：\n",
    "# 求解ln{∑zp(X,Z∣θ)}很难，通过Jensen不等式，或者KL散度ß能够求到其下界\n",
    "# q(Z)是潜变量的分布\n",
    "# 定义的L(q,θ)和KL(q∥p)使得相加能够等于lnp(X∣θ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "证明：\n",
    "\n",
    "有条件概率密度$p(\\mathbf{X,Z} \\mid \\mathbf{θ}) = p(\\mathbf{Z} \\mid \\mathbf{X,θ}) \\times p(\\mathbf{X} \\mid \\mathbf{θ})$\n",
    "\n",
    "对等式两边同时取ln，得\n",
    "\n",
    "$\\ln p(\\mathbf{X,Z} \\mid \\mathbf{θ}) = \\ln p(\\mathbf{Z} \\mid \\mathbf{X,θ}) + \\ln p(\\mathbf{X} \\mid \\mathbf{θ})$\n",
    "\n",
    "继而得：\n",
    "\n",
    "$\\ln p(\\mathbf{X} \\mid \\mathbf{θ}) = \\ln p(\\mathbf{X,Z} \\mid \\mathbf{θ}) - \\ln p(\\mathbf{Z} \\mid \\mathbf{X,θ}) = \\ln \\left\\{\\frac{p(\\mathbf{X,Z} \\mid \\mathbf{θ})}{p(\\mathbf{Z} \\mid \\mathbf{X,θ})}\\right\\}$\n",
    "\n",
    "再有\n",
    "\n",
    "$$\\mathcal{L}(q,\\mathbf{θ}) = \\sum_{\\mathbf{Z}}q(\\mathbf{Z}) \\ln \\left\\{\\frac{p(\\mathbf{X,Z} \\mid \\mathbf{θ})}{q(\\mathbf{Z})}\\right\\}$$\n",
    "    $$KL(q\\|p) = - \\sum_{\\mathbf{Z}}q(\\mathbf{Z}) \\ln \\left\\{\\frac{p(\\mathbf{Z} \\mid \\mathbf{X,θ})}{q(\\mathbf{Z})}\\right\\}$$\n",
    "    \n",
    "两式相加，得：\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathcal{L}(q,\\mathbf{θ}) + KL(q\\|p) &= \\sum_{\\mathbf{Z}}q(\\mathbf{Z}) \\ln \\left\\{\\frac{p(\\mathbf{X,Z} \\mid \\mathbf{θ})}{q(\\mathbf{Z})}\\right\\} - \\sum_{\\mathbf{Z}}q(\\mathbf{Z}) \\ln \\left\\{\\frac{p(\\mathbf{Z} \\mid \\mathbf{X,θ})}{q(\\mathbf{Z})}\\right\\} \\\\\n",
    "&= \\sum_{\\mathbf{Z}}q(\\mathbf{Z}) \\ln \\left\\{\\frac{p(\\mathbf{X,Z} \\mid \\mathbf{θ})}{p(\\mathbf{Z} \\mid \\mathbf{X,θ})}\\right\\} \\\\\n",
    "&= \\sum_{\\mathbf{Z}}q(\\mathbf{Z}) \\ln p(\\mathbf{X} \\mid \\mathbf{θ})\n",
    "\\end{align*}$$\n",
    "\n",
    "因潜变量的分布$\\sum_{\\mathbf{Z}}q(\\mathbf{Z}) = 1$，故而得正$L(q,\\mathbf{θ}) + KL(q\\|p) = \\ln p(\\mathbf{X} \\mid \\mathbf{θ})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL散度\n",
    "\n",
    "衡量的是两个分布之间的距离，也是相对熵，也可以理解为相似度\n",
    "\n",
    "离散\n",
    "\n",
    "$$KL(p\\|q) = \\sum p(\\mathbf{x}) \\ln \\left(\\frac{q(\\mathbf{x})}{p(\\mathbf{x})}\\right)$$\n",
    "\n",
    "连续\n",
    "\n",
    "$$KL(p\\|q) = \\int p(\\mathbf{x}) \\ln \\left(\\frac{q(\\mathbf{x})}{p(\\mathbf{x})}\\right)d\\mathbf{x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL距离一定>=0，通过Jensen不等式证明 其实想想也是，两个分布的距离，怎么看也不可能为负数啊，距离为负数，那只是表示的是方向，是个向量了\n",
    "# 当q(x)=p(x)，其KL距离为0"
   ]
  },
  {
   "attachments": {
    "KL1.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![KL1.jpg](attachment:KL1.jpg)"
   ]
  },
  {
   "attachments": {
    "KL2.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![KL2.jpg](attachment:KL2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM\n",
    "\n",
    "* E步：$q(\\mathbf{Z}) = p(\\mathbf{Z} \\mid \\mathbf{X},\\mathbf{θ}^{old})$代入，则有\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathcal{L}(q,\\mathbf{θ}) &= \\sum_{\\mathbf{Z}}q(\\mathbf{Z}) \\ln \\left\\{\\frac{p(\\mathbf{X,Z} \\mid \\mathbf{θ})}{q(\\mathbf{Z})}\\right\\} \\\\\n",
    "&= \\sum_{\\mathbf{Z}}p(\\mathbf{Z} \\mid \\mathbf{X},\\mathbf{θ}^{old}) \\ln \\left\\{\\frac{p(\\mathbf{X,Z} \\mid \\mathbf{θ})}{p(\\mathbf{Z} \\mid \\mathbf{X},\\mathbf{θ}^{old})}\\right\\} \\\\\n",
    "&= \\sum_{\\mathbf{Z}} p(\\mathbf{Z} \\mid \\mathbf{X},\\mathbf{θ}^{old}) \\ln p(\\mathbf{X,Z} \\mid \\mathbf{θ}) - \\sum_{\\mathbf{Z}} p(\\mathbf{Z} \\mid \\mathbf{X},\\mathbf{θ}^{old}) \\ln p(\\mathbf{Z} \\mid \\mathbf{X},\\mathbf{θ}^{old}) \\\\\n",
    "&= \\mathcal{Q}(\\mathbf{θ},\\mathbf{θ}^{old}) + const\n",
    "\\end{align*}$$\n",
    "\n",
    "* M步：通过初始化的$θ^{old}$求得模型，才利用梯度为0，迭代优化使得$\\mathcal{Q}(\\mathbf{θ},\\mathbf{θ}^{old})$最大化的参数$\\widehat{θ}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：\n",
    "# 已知N个样本X = {x1,…,xN}，潜变量Z = {z1,…,zN}，参数θ = {π1,…,πk,μ1,…,μk,Σ1,…,Σk}\n",
    "# p(Z∣X,θold)：是在已知数据X和初始值θ条件下Z的概率\n",
    "# 从p(Z∣X,θold)lnp(Z∣X,θold)这个式子看出是信息熵，是一个常数\n",
    "# 而从lnp(X,Z∣θ)p(Z∣X,θ^old)看出是对给定X,θ^old的函数lnp(X,Z|θ)对Z求期望，也就是E[ln(X,Z∣θ)|X,θ^old]，也就是为什么说EM算法，\n",
    "# 在求最大化期望的原因了\n",
    "# 离散函数的期望为E[ln(x)] = Σln(x)p(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：当q(Z)=p(Z∣X,θold)时，即KL(p∥q)=0\n",
    "# ∑Zp(Z∣X,θold)lnp(Z∣X,θold)是信息熵，是一个常数\n",
    "# 说明：我们优化的目标函数是lnp(X∣θ)，而lnp(X∣θ)=L(q,θ)+KL(q∥p)，故有\n",
    "# lnp(X∣θ)>=L(q,θ)，我们可以令KL(p∥q)=0，那就变成优化其下界(下界最大化)，也就是优化\n",
    "# Q(θ,θold)\n",
    "# θ发生变化的同时，KL(p∥q)也会增加，随着L(q,θ)值得上升，lnp(X∣θ)也跟着上升\n",
    "# EM的求解思路有两种：\n",
    "# 1、Jensen不等式\n",
    "# 2、KL散度+L似然函数\n",
    "# 本质上都是一样的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM总结：\n",
    "\n",
    "* E步：用$\\mathbf{θ}^{old}$，然后计算\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathcal{Q}(\\mathbf{θ},\\mathbf{θ}^{old}) &= \\sum_{\\mathbf{Z}} \\ln p(\\mathbf{X,Z} \\mid \\mathbf{θ}) p(\\mathbf{Z} \\mid \\mathbf{X},\\mathbf{θ}^{old})  \\\\\n",
    "&= E_{\\mathbf{Z}}\\left[\\ln p(\\mathbf{X,Z} \\mid \\mathbf{θ}) \\mid \\mathbf{X},\\mathbf{θ}^{old}\\right]\n",
    "\\end{align*}$$\n",
    "\n",
    "* M步\n",
    "\n",
    "$$\\mathbf{θ}^{new} = \\arg \\max_{\\mathbf{θ}}\\mathcal{Q}(\\mathbf{θ},\\mathbf{θ}^{old})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：Q(θ,θold)实际上在对Z求期望"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM算法总结：\n",
    "# 1、写出似然函数，优化目标\n",
    "# 2、使用最大似然直接优化只有观测值的目标函数很困难(存在ln(a+b+...+n)的对数求导困难)\n",
    "# 3、利用KL散度和L似然下界的思路，通过令KL=0，去优化目标函数的下界L\n",
    "# 4、该下界函数其实是一个对Z的期望\n",
    "# 5、Z是潜变量的分布，需要引入潜变量，重写写出包含观测值和潜变量的似然函数\n",
    "# 6、再对这个似然函数取对数\n",
    "# 7、对这个对数函数求Z得期望，得到我们要优化的目标函数\n",
    "# 8、该期望优化函数中包含γ(znk)，而这个值在GMM中是后验概率，可以通过初始化θ值求得，这一步是E步 因为是期望函数\n",
    "# 9、将旧值代入期望函数，去迭代优化得到使得期望函数最大化的θ值，这步是M步\n",
    "# 10、不断迭代，直到函数收敛"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "应用于GMM\n",
    "\n",
    "* 似然函数\n",
    "\n",
    "$$p(\\mathbf{X,Z} \\mid \\mathbf{μ,Σ,π}) = \\prod_{n=1}^N\\prod_{k=1}^K\\pi_k^{z_{n,k}}\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)^{z_{n,k}}$$\n",
    "\n",
    "    对比：\n",
    "    \n",
    "$$p(\\mathbf{X}\\mid\\mathbf{μ,Σ,\\pi}) = \\prod_{n=1}^N \\ln \\left\\{{\\sum_{k=1}^K\\pi_k\\mathcal{N}(\\mathbf{x_n}\\mid\\mathbf{μ_k,Σ_k})}\\right\\}$$\n",
    "\n",
    "* log似然\n",
    "\n",
    "$$\\ln p(\\mathbf{X,Z} \\mid \\mathbf{μ,Σ,π}) = \\sum_{n=1}^N\\sum_{k=1}^Kz_{n,k}\\left\\{\\ln \\pi_k + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)\\right\\}$$\n",
    "    \n",
    "    \n",
    "    对比:\n",
    "    \n",
    "$$\\ln p(\\mathbf{X}\\mid\\mathbf{μ,Σ,\\pi}) = \\sum_{n=1}^N \\ln \\left\\{{\\sum_{k=1}^K\\pi_k\\mathcal{N}(\\mathbf{x_n}\\mid\\mathbf{μ_k,Σ_k})}\\right\\}$$\n",
    "\n",
    "* 期望\n",
    "\n",
    "$$E_{\\mathbf{Z}}\\left[\\ln p(\\mathbf{X,Z} \\mid \\mathbf{μ,Σ,π}) \\right] = \\sum_{n=1}^N\\sum_{k=1}^Kγ\\left(z_{n,k}\\right)\\left\\{\\ln \\pi_k + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)\\right\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：\n",
    "# 独立观测数据X的似然函数等效于，引入潜变量Z后的联立似然函数\n",
    "# 对于公式p(X∣μ,Σ,π)=∏n=1Nln{∑k=1KπkN(xn∣μk,Σk)}中的ln的解释是对单独一个观测数据取对数，而∏n=1N则是N个独立观测数据组合成混合高斯模型\n",
    "# 也是独立观测数据X时的似然函数，自然想到再次取对数，得到其对数似然，但该对数似然比较难求导\n",
    "# 故而我们引入隐变量后，对数似然函数也有些变化，但却很方便求导，对数跑到Σ里面了\n",
    "# 对数原始对数似然函数不方便求导的两种解释：\n",
    "# 其一：是通过引入的潜变量Z，写出联合X,Z的似然函数，再取其对数，可得联立X,Z的对数似然，该对数似然，对数在Σ里面，求导变得简单(其理论是结合KL距离\n",
    "# 和对应的L(q,θ)也就是期望支撑，也就是说我们需要求对数似然的期望，这个期望也就是EM算法优化的目标函数的下界函数)\n",
    "# 其二：另一种方法就是利用jensen不等式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推导log似然：\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\ln p(\\mathbf{X,Z} \\mid \\mathbf{μ,Σ,π}) &= \\ln \\prod_{n=1}^N\\prod_{k=1}^K\\pi_k^{z_{n,k}}\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)^{z_{n,k}} \\\\\n",
    "&= \\ln \\left\\{\\prod_{k=1}^K\\pi_k^{z_{1,k}}\\mathcal{N}(\\mathbf{x}_1 \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)^{z_{1,k}} \\times \\dots \\times \\prod_{k=1}^K\\pi_k^{z_{n,k}}\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)^{z_{n,k}}\\right\\} \\\\\n",
    "&= \\ln \\prod_{k=1}^K\\pi_k^{z_{1,k}}\\mathcal{N}(\\mathbf{x}_1 \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)^{z_{1,k}} + \\dots + \\ln \\prod_{k=1}^K\\pi_k^{z_{n,k}}\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)^{z_{n,k}} \\\\\n",
    "&= \\sum_{n=1}^N \\ln \\prod_{k=1}^K \\pi_k^{z_{n,k}}\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)^{z_{n,k}} \\\\\n",
    "&= \\sum_{n=1}^N \\ln \\left\\{\\pi_1^{z_{n,1}}\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_1,\\mathbf{Σ}_1)^{z_{n,1}} \\times \\dots \\times  \\pi_K^{z_{n,K}}\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_K,\\mathbf{Σ}_K)^{z_{n,K}}\\right\\} \\\\\n",
    "&= \\sum_{n=1}^N \\left\\{\\ln \\pi_1^{z_{n,1}}\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_1,\\mathbf{Σ}_1)^{z_{n,1}} + \\dots + \\ln \\pi_K^{z_{n,K}}\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_K,\\mathbf{Σ}_K)^{z_{n,K}}\\right\\} \\\\\n",
    "&= \\sum_{n=1}^N \\sum_{k=1}^K \\ln \\pi_K^{z_{n,k}}\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)^{z_{n,k}} \\\\\n",
    "&= \\sum_{n=1}^N \\sum_{k=1}^K \\left\\{\\ln \\pi_K^{z_{n,k}} + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)^{z_{n,k}} \\right\\} \\\\\n",
    "&= \\sum_{n=1}^N\\sum_{k=1}^Kz_{n,k}\\left\\{\\ln \\pi_k + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)\\right\\}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推导log似然期望：\n",
    "\n",
    "$$\\begin{align*}\n",
    "E_{\\mathbf{Z}}\\left[\\ln p(\\mathbf{X,Z} \\mid \\mathbf{μ,Σ,π}) \\right] &= \\sum_{\\mathbf{Z}}p(\\mathbf{Z} \\mid \\mathbf{X,μ,Σ,\\pi}) \\ln p(\\mathbf{X,Z} \\mid \\mathbf{μ,Σ,\\pi}) \\\\\n",
    "&= \\sum_{\\mathbf{Z}}\\frac{p(\\mathbf{X,Z} \\mid \\mathbf{μ,Σ,\\pi})}{p(\\mathbf{X} \\mid \\mathbf{μ,Σ,\\pi})}\\ln p(\\mathbf{X,Z} \\mid \\mathbf{μ,Σ,\\pi})\n",
    "\\end{align*}$$\n",
    "\n",
    "由\n",
    "\n",
    "$$p(\\mathbf{X,Z} \\mid \\mathbf{μ,Σ,π}) = \\prod_{n=1}^N\\prod_{k=1}^K\\pi_k^{z_{n,k}}\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)^{z_{n,k}}$$\n",
    "$$p(\\mathbf{X}\\mid\\mathbf{μ,Σ,\\pi}) = \\prod_{n=1}^N\\sum_{j=1}^K\\pi_j\\mathcal{N}(\\mathbf{x}_n\\mid\\mathbf{μ}_j,\\mathbf{Σ}_j)$$\n",
    "$$\\ln p(\\mathbf{X,Z} \\mid \\mathbf{μ,Σ,π}) = \\sum_{n=1}^N\\sum_{k=1}^Kz_{n,k}\\left\\{\\ln \\pi_k + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)\\right\\}$$\n",
    "\n",
    "继而有：\n",
    "\n",
    "$$\\begin{align*}\n",
    "E_{\\mathbf{Z}}\\left[\\ln p(\\mathbf{X,Z} \\mid \\mathbf{μ,Σ,π}) \\right] &= \\sum_{\\mathbf{Z}}\\frac{\\prod_{n=1}^N\\prod_{k=1}^K\\pi_k^{z_{n,k}}\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)^{z_{n,k}}}{\\prod_{n=1}^N\\sum_{j=1}^K\\pi_j\\mathcal{N}(\\mathbf{x}_n\\mid\\mathbf{μ}_j,\\mathbf{Σ}_j)}\\sum_{n=1}^N\\sum_{k=1}^Kz_{n,k}\\left\\{\\ln \\pi_k + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)\\right\\} \\\\\n",
    "&= \\frac{\\pi_k\\mathcal{N}(\\mathbf{x} \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)}{\\sum_{j=1}^K\\pi_j\\mathcal{N}(\\mathbf{x}\\mid\\mathbf{μ}_j,\\mathbf{Σ}_j)}\\sum_{n=1}^N\\sum_{k=1}^K\\left\\{\\ln \\pi_k + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)\\right\\} \\\\\n",
    "&= γ(z_{n,k})\\sum_{n=1}^N\\sum_{k=1}^K\\left\\{\\ln \\pi_k + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)\\right\\} \\\\\n",
    "&= \\sum_{n=1}^N\\sum_{k=1}^Kγ\\left(z_{n,k}\\right)\\left\\{\\ln \\pi_k + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)\\right\\}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求解$\\mathbf{μ_k,Σ_k,\\pi_k}$：\n",
    "\n",
    "因$$\\begin{align*}\n",
    "\\mathcal{Q}(\\mathbf{θ},\\mathbf{θ}^{old}) &= E_{\\mathbf{Z}}\\left[\\ln p(\\mathbf{X,Z} \\mid \\mathbf{μ,Σ,π}) \\right] \\\\\n",
    "&= \\sum_{n=1}^N\\sum_{k=1}^Kγ\\left(z_{n,k}\\right)\\left\\{\\ln \\pi_k + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)\\right\\}\n",
    "\\end{align*}$$\n",
    "\n",
    "另外，我们有：\n",
    "\n",
    "责任:\n",
    "\n",
    "$$γ(z_{n,k}) = \\frac{\\pi_k\\mathcal{N}(\\mathbf{x}_n\\mid\\mathbf{μ}_k,\\mathbf{Σ}_k)}{\\sum_{j=1}^K\\pi_j\\mathcal{N}(\\mathbf{x}_n\\mid\\mathbf{μ}_j,\\mathbf{Σ}_j)}$$是一个常数，无需拆开求导\n",
    "\n",
    "多元高斯分布：\n",
    "\n",
    "$$\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k) = \\frac{1}{\\sqrt{(2\\pi)^d|\\mathbf{Σ}_k|}}e^{\\left[-\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)^TΣ_k^{-1}(\\mathbf{x}_n-\\mathbf{μ}_k)\\right]}$$\n",
    "\n",
    "我们需要优化Q函数，继而优化$\\sum_{n=1}^N\\sum_{k=1}^Kγ\\left(z_{n,k}\\right)\\left\\{\\ln \\pi_k + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)\\right\\}$，求解最优$\\mathbf{μ_k,Σ_k,\\pi_k}$\n",
    "\n",
    "将$\\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)$代入$\\sum_{n=1}^N\\sum_{k=1}^Kγ\\left(z_{n,k}\\right)\\left\\{\\ln \\pi_k + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)\\right\\}$，进行化简，得\n",
    "\n",
    "$$\\sum_{n=1}^N\\sum_{k=1}^Kγ\\left(z_{n,k}\\right)\\left\\{\\ln \\pi_k + \\ln \\mathcal{N}(\\mathbf{x}_n \\mid \\mathbf{μ}_k,\\mathbf{Σ}_k)\\right\\} = \\sum_{n=1}^N\\sum_{k=1}^Kγ\\left(z_{n,k}\\right)\\left\\{\\ln \\pi_k + \\left[-\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\mathbf{Σ}_k^{-1}(\\mathbf{x}_n-\\mathbf{μ}_k)\\right] - \\frac{d}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln|\\mathbf{Σ}_k|\\right\\}$$\n",
    "\n",
    "求解$\\mathbf{μ_k}$，对$\\mathbf{μ_k}$求偏导，得\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{Q}(\\mathbf{θ},\\mathbf{θ}^{old})}{\\partial \\mathbf{μ}_k} &= \\sum_{n=1}^N\\sum_{k=1}^Kγ\\left(z_{n,k}\\right)(\\mathbf{x}_n-\\mathbf{μ}_k)\\mathbf{Σ}_k^{-1} = 0\n",
    "\\end{align*}$$\n",
    "\n",
    "说明：此处的$\\mathbf{Σ}_k^{-1}$和$γ\\left(z_{n,k}\\right)$可以通过初始值求得，继而有：\n",
    "\n",
    "$$\\sum_{n=1}^N\\sum_{k=1}^Kγ\\left(z_{n,k}\\right)(\\mathbf{x}_n-\\mathbf{μ}_k) = 0 $$\n",
    "$$\\Downarrow$$\n",
    "$$\\sum_{n=1}^Nγ\\left(z_{n,k}\\right)\\mathbf{x}_n = \\sum_{n=1}^Nγ\\left(z_{n,k}\\right)\\mathbf{μ}_k$$\n",
    "\n",
    "定义$N_k = \\sum_{n=1}^Nγ(z_{n,k})$，则有：\n",
    "\n",
    "$$\\sum_{n=1}^Nγ\\left(z_{n,k}\\right)\\mathbf{x}_n = N_k\\mathbf{μ}_k$$\n",
    "\n",
    "继而得到：\n",
    "\n",
    "$$\\widehat{\\mathbf{μ}}_k = \\frac{1}{N_k}\\sum_{n=1}^Nγ(z_{n,k})\\mathbf{x_n}$$\n",
    "\n",
    "求解$\\mathbf{Σ_k}$，对$\\mathbf{Σ_k}$求偏导，\n",
    "\n",
    "这里涉及到对逆矩阵$\\mathbf{Σ_k}^{-1}$求导，\n",
    "\n",
    "我们根据如下推导：\n",
    "\n",
    "$$\\mathbf{0} = \\mathbf{I}' = [\\mathbf{Σ}_k\\mathbf{Σ}_k^{-1}]' = \\mathbf{Σ}_{k}'\\mathbf{Σ}_k^{-1} + \\mathbf{Σ}_k[\\mathbf{Σ}_k^{-1}]'$$\n",
    "$$\\Downarrow$$\n",
    "$$[\\mathbf{Σ}_k^{-1}]' = -\\mathbf{Σ}_k^{-1}\\mathbf{Σ}_k'\\mathbf{Σ}_k^{-1}$$\n",
    "\n",
    "且有行列式对矩阵的求导，根据matrix cookbook有：\n",
    "\n",
    "$$\\frac{\\partial \\ln |\\mathbf{Σ}_k|}{\\partial \\mathbf{Σ}_k} = 2\\mathbf{Σ}_k^{-1} - (\\mathbf{Σ}_k^{-1}\\cdot\\mathbf{I}) = \\mathbf{Σ}_k^{-1}$$\n",
    "$$\\mathbf{Σ}_k' = \\frac{\\partial \\mathbf{I}\\mathbf{Σ}_k}{\\partial \\mathbf{Σ}_k} = \\mathbf{I}$$\n",
    "\n",
    "\n",
    "得：\n",
    "\n",
    "已知$\\mathbf{Σ}_k$是协方差矩阵，且可逆，则有$\\mathbf{Σ}_k$是正定矩阵\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\frac{\\partial \\mathcal{Q}(\\mathbf{θ},\\mathbf{θ}^{old})}{\\partial \\mathbf{Σ}_k} &= \\sum_{n=1}^N\\sum_{k=1}^Kγ\\left(z_{n,k}\\right)\\left\\{-\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\left(-\\mathbf{Σ}_k^{-1}\\mathbf{Σ}_k'\\mathbf{Σ}_k^{-1}\\right) - \\frac{1}{2}\\mathbf{Σ}_k^{-1}\\right\\} \\\\\n",
    "&= \\sum_{n=1}^N\\sum_{k=1}^Kγ\\left(z_{n,k}\\right)\\left\\{\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\left(\\mathbf{Σ}_k^{-1}\\mathbf{Σ}_k'\\mathbf{Σ}_k^{-1}\\right) - \\frac{1}{2}\\mathbf{Σ}_k^{-1}\\right\\} =0 \\\\\n",
    "\\end{align*}$$\n",
    "$$\\Downarrow$$\n",
    "$$\\sum_{n=1}^Nγ\\left(z_{n,k}\\right)(\\mathbf{x}_n-\\mathbf{μ}_k)(\\mathbf{x}_n-\\mathbf{μ}_k)^T = \\sum_{n=1}^Nγ\\left(z_{n,k}\\right)\\mathbf{Σ}_k$$\n",
    "$$\\Downarrow$$\n",
    "$$\\sum_{n=1}^Nγ\\left(z_{n,k}\\right)(\\mathbf{x}_n-\\mathbf{μ}_k)(\\mathbf{x}_n-\\mathbf{μ}_k)^T = N_k\\mathbf{Σ}_k$$\n",
    "$$\\Downarrow$$\n",
    "$$\\widehat{\\mathbf{Σ}}_k = \\frac{1}{N_k}\\sum_{n=1}^Nγ(z_{n,k})(\\mathbf{x_n} - \\mathbf{μ}_k)(\\mathbf{x_n} - \\mathbf{μ}_k)^T$$\n",
    "\n",
    "求解$\\pi_k$，因有$\\sum_{k=1}^K\\pi_k = 1$的约束条件，需要结合拉格朗日乘子法求解，故而将目标函数转换为如下：\n",
    "\n",
    "$$\\sum_{n=1}^N\\sum_{k=1}^Kγ\\left(z_{n,k}\\right)\\left\\{\\ln \\pi_k + \\left[-\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\mathbf{Σ}_k^{-1}(\\mathbf{x}_n-\\mathbf{μ}_k)\\right] - \\frac{d}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln|\\mathbf{Σ}_k|\\right\\} + λ\\left(\\sum_{k=1}^K\\pi_k - 1\\right)$$\n",
    "\n",
    "上式对$\\pi_k$求导，则有：\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{Q}(\\mathbf{θ},\\mathbf{θ}^{old})}{\\partial \\pi_k} = \\sum_{n=1}^Nγ\\left(z_{n,k}\\right)\\frac{1}{\\pi_k} + λ = 0$$\n",
    "\n",
    "对上式两边同时乘以$\\pi_k$，得：\n",
    "\n",
    "$$N_k + λ\\pi_k = 0$$\n",
    "\n",
    "对所有$k$求和，有：\n",
    "\n",
    "$$\\sum_{k=1}^KN_k + λ\\sum_{k=1}^K\\pi_k = 0$$\n",
    "\n",
    "由$\\sum_{k=1}^K\\pi_k = 1$，可得：\n",
    "\n",
    "$$λ = - N$$\n",
    "\n",
    "继而有：\n",
    "\n",
    "$$\\widehat{\\pi}_k = \\frac{N_k}{N}$$\n",
    "\n",
    "说明：定义的$N_k = \\sum_{n=1}^Nγ(z_{n,k})$是属于$k$个聚类的有效点的数量，可以体会下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "证明GMM的目标函数不是凸函数\n",
    "\n",
    "假定GMM的目标函数是凸函数，也就是组成期望函数的三个函数都要是凸函数，继而证明$\\ln \\pi_k$，$-\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\mathbf{Σ}_k^{-1}(\\mathbf{x}_n-\\mathbf{μ}_k)$ 和 $-\\frac{1}{2}\\ln|\\mathbf{Σ}_k|$是凸函数\n",
    "\n",
    "先证明$\\ln \\pi_k$是凸函数，我们使用对$\\pi_k$的二阶导Hessian矩阵半正定来证明：\n",
    "\n",
    "设$\\pi_k ≠ 0 $，且$\\pi_k$是一个常数\n",
    "\n",
    "$$\\nabla_{\\pi_k}(\\ln \\pi_k) = \\frac{1}{\\pi_k}$$\n",
    "\n",
    "$$\\Downarrow$$\n",
    "\n",
    "$$\\nabla_{\\pi_k}^2(\\ln \\pi_k) = -\\frac{1}{\\pi_k^2} < 0$$\n",
    "\n",
    "正得$\\ln \\pi_k$是非凸函数，二阶导对$\\pi_k$ 有$\\mathbf{z}^T\\nabla_{\\pi_k}^2(\\ln \\pi_k)\\mathbf{z} < 0$，联合一阶导存在局部极大值\n",
    "\n",
    "再来证明$-\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\mathbf{Σ}_k^{-1}(\\mathbf{x}_n-\\mathbf{μ}_k)$是凸函数：\n",
    "\n",
    "我们有$\\mathbf{Σ}_k$是正定对称矩阵，且可逆，则有：\n",
    "\n",
    "$$\\mathbf{Σ}_k\\cdot\\mathbf{Σ}_k^{-1} = \\mathbf{I}$$\n",
    "\n",
    "因有$\\mathbf{Σ}_k$和$\\mathbf{I}$为正定矩阵，则推出$\\mathbf{Σ}_k^{-1}$也为对称正定矩阵\n",
    "\n",
    "$$\\nabla_{\\mathbf{μ}_k}\\left[-\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\mathbf{Σ}_k^{-1}(\\mathbf{x}_n-\\mathbf{μ}_k)\\right] = \\left(\\mathbf{x}_n-\\mathbf{μ}_k\\right)\\mathbf{Σ}_k^{-1}$$\n",
    "\n",
    "$$\\Downarrow$$\n",
    "\n",
    "$$\\nabla_{\\mathbf{μ}_k}^2\\left[-\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\mathbf{Σ}_k^{-1}(\\mathbf{x}_n-\\mathbf{μ}_k)\\right] = -\\mathbf{Σ}_k^{-1} \\prec \\mathbf{0}$$\n",
    "\n",
    "正得对于$\\mathbf{μ}_k$，$-\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\mathbf{Σ}_k^{-1}(\\mathbf{x}_n-\\mathbf{μ}_k)$是非凸函数\n",
    "\n",
    "$$\\nabla_{\\mathbf{Σ}_k}\\left[-\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\mathbf{Σ}_k^{-1}(\\mathbf{x}_n-\\mathbf{μ}_k)\\right] = \\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\left(\\mathbf{Σ}_k^{-1}\\mathbf{Σ}_k'\\mathbf{Σ}_k^{-1}\\right)$$\n",
    "\n",
    "$$\\Downarrow$$\n",
    "\n",
    "$$\\nabla_{\\mathbf{Σ}_k}^2\\left[-\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\mathbf{Σ}_k^{-1}(\\mathbf{x}_n-\\mathbf{μ}_k)\\right] = \\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)^T(\\mathbf{x}_n-\\mathbf{μ}_k)2\\left({\\mathbf{Σ}_k^{-1}}\\right)\\left(\\mathbf{Σ}_k^{-1}\\mathbf{Σ}’\\mathbf{Σ}_k^{-1}\\right) = (\\mathbf{x}_n-\\mathbf{μ}_k)^T(\\mathbf{x}_n-\\mathbf{μ}_k)\\left[{\\mathbf{Σ}_k^{-1}}\\right]^3 > 0$$\n",
    "\n",
    "故而有$\\mathbf{z}^T\\nabla_{\\mathbf{Σ}_k}^2\\left[-\\frac{1}{2}(\\mathbf{x}_n-\\mathbf{μ}_k)^T\\mathbf{Σ}_k^{-1}(\\mathbf{x}_n-\\mathbf{μ}_k)\\right]\\mathbf{z} = \\frac{1}{2}\\left(\\mathbf{z}^T(\\mathbf{x}_n-\\mathbf{μ}_k)\\right)^2\\left[{\\mathbf{Σ}_k^{-1}}\\right]^3 > 0$，证得对于$\\mathbf{Σ}_k$是凸函数\n",
    "\n",
    "而对于函数$-\\frac{1}{2}\\ln|\\mathbf{Σ}_k|$，同样有$\\nabla_{\\mathbf{Σ}_k}^2 > 0$ 是凸函数\n",
    "\n",
    "所以对于高斯混合模型是凸函数和非凸函数的组成，也就是有凸也有凹，且存在鞍点，所以该函数是非凸函数，一般来说存在局部最优解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最终得到局部最优解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PMRL笔记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、一个观测变量的概率密度可以通过引入潜变量，求其边缘概率得到，而边缘概率里的联合概率\n",
    "# 可以通过条件概率密度来表示进一步求得\n",
    "# 2、指示变量，用于被指定分配到哪个聚类，在GMM中，也就是zk这个元素属于哪个高斯分布，如果属于第k\n",
    "# 个高斯分布，那zk就为1，其余的为0，以此来表示，或者说叫做指示被分配到哪个高斯\n",
    "# 通俗点将，如果这个数据被分到第k个分类，那么rnk=1，那么rn(k-1)=0\n",
    "# 3、k-means收敛直到聚类中心不再改变，或者设置了停止条件\n",
    "# 4、k-means的目标函数并非凸函数，所以算法可能只收敛到一个局部最小值而不是全局最小值\n",
    "# 5、选择合适的初始值，能够使得函数快速收敛，一般为随机数据点组成的子集\n",
    "# 6、k-means根据目标函数需要计算每个样本点，大样本时，速度显然会比较慢，加速k-means的方法也有很多\n",
    "# 比如：相邻的数据点应属于同一个子树。还有使用距离的三角不等式，可以避免不必要的计算\n",
    "# 7、同样我们也可以使用类似梯度下降法，迭代求μk\n",
    "# 8、图像压缩使用k-means方法，每个像素存储的是属于哪个k分类，和k个聚类中心μk的亮度值\n",
    "# 也就是说只要存储属于哪个分类，以及这个分类的亮度值，共24K+Nlog2K bit\n",
    "# 9、高斯混合模型里的观测数据[x1,x2,...,xn]，每一个观测数据，对应一个潜变量z，即有[z1,z2,...,zn]个潜变量\n",
    "# 与之对应\n",
    "# 10、高斯混合模型中的γ(zk)的理解，πk可以看做是zk=1的先验概率，而γ(zk)看成是看到观测数据x之后，对应的后验概率\n",
    "# 也可以理解为分量k对于“解释”观测值x得“责任”，或者说是共享度\n",
    "# 11、当混合高斯模型中的其中一个高斯分布退化为只有一个数据点时，这个数据点即为它自己的均值μ1，而σ1则趋于0，\n",
    "# 而另一个高斯分布则正常，这种情况的高斯混合使用最大似然估计进行聚类会有过拟合的现象\n",
    "# 12、出现上述这种情况，我们可以采用贝叶斯方法，或者仍然使用最大似然，但当我们检测到高斯分量收缩到一个点时，\n",
    "# 将其均值重新设定一个随机选择值，方差重新定义一个较大的值，再继续优化\n",
    "# 13、高斯混合模型中的γ(zk)表示的后验概率，这个数据点属于哪个聚类的可能性大小，当同时属于多个聚类的可能性都很大时\n",
    "# 在绘制图形时，可以使用不同的颜色标记\n",
    "# 14、因高斯混合模型使用EM算法如果初始值没选好，可能会经过更多的迭代，计算量也更大，通常，我们先使用k-means算法找到\n",
    "# 混合高斯模型的一个合适的初始值，然后再使用EM算法进行优化\n",
    "# k-means每次只是需要找质心，而高斯混合模型每次都需要重新生成新的高斯分布，自然会慢很多\n",
    "# 通过k-means找到初始化质心，然后再根据这个质心找到样本的协方差，而混合系数为类别样本占比\n",
    "# 15、目标函数为对数似然函数，会存在多个局部极大值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从K-means目标函数求得的$μ_k = \\frac{\\sum_nr_{nk}x_n}{\\sum_nr_{nk}}$可以看出，其表示的是类别$k$的所有数据点的均值\n",
    "$\\sigma_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析解：是一个固定的值\n",
    "# 闭合解：是一个区间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM算法有点类似两个人在赛跑，一个人在前，一个在后，后面的人不断在赶前面的人\n",
    "# 后面的人赶上一段，前面的人也跑了一段，之间总是有这么一个差距，而E步就相当于\n",
    "# 前面的人不跑了在等后面的人赶上，再跑，速度比后面的人快，很快就又拉开了距离，\n",
    "# 这样不断重复，直到前面的人先到达终点，后面的人最后也到达终点，算法收敛"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
