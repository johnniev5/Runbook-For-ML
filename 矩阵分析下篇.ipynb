{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征分解复习\n",
    "# 对称矩阵特征分解，不需要要求特征值都相同\n",
    "# 对于任意矩阵是否存在类似的分解？- 奇异值分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD理论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD分解：特征分解的广义化\n",
    "\n",
    "任何$\\mathbf{A}∈\\mathbb{R}^{m \\times n}$的矩阵可以被分解为\n",
    "\n",
    "$$\\mathbf{A}=\\mathbf{UΣV^T}$$\n",
    "\n",
    "其中$\\mathbf{U}∈\\mathbb{R}^{m \\times m}$和$\\mathbf{V}∈\\mathbb{R}^{n \\times n}$是正交矩阵。定义$p=\\min(m,n)$，则有\n",
    "\n",
    "$$\\mathbf{Σ}(i,j)=\n",
    "\\begin{cases}\n",
    "    \\begin{align*}\n",
    "    \\sigma_i,\\hspace{0.3cm}&i=j \\\\\n",
    "    0,\\hspace{0.3cm}&i≠j\n",
    "    \\end{align*}\n",
    "\\end{cases}$$\n",
    "\n",
    "$$\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_p > 0$$\n",
    "\n",
    "具体：\n",
    "\n",
    "$$\\mathbf{Σ}=\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "    \\mathbf{Σ}_p & \\mathbf{0} \\\\\n",
    "    \\mathbf{0} & \\mathbf{0}\n",
    "\\end{matrix}\n",
    "\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD分解的三种形式\n",
    "\n",
    "第一种形式：分块型\n",
    "\n",
    "假定r表示非零奇异值的数量，即$r=Rank(\\mathbf{A})$。对奇异值进行排序：\n",
    "\n",
    "$$\\underbrace{\\sigma_1 \\ge \\dots \\ge \\sigma_r}_\\text{r} > \\underbrace{\\sigma_{r+1} = \\dots = \\sigma_p}_\\text{p-r} = 0$$\n",
    "\n",
    "分块式SVD可以表示为\n",
    "\n",
    "$$\\begin{align*}\n",
    "   A&=\\mathbf{UΣV^T} \\\\\n",
    "    &=\\underbrace{[\\mathbf{U_1U_2}]}_{\\mathbf{U}}\n",
    "    \\underbrace{\\left[\n",
    "        \\begin{matrix}\n",
    "            \\mathbf{Σ_1} & \\mathbf{0}_{r \\times (n-r)} \\\\\n",
    "            \\mathbf{0}_{(m-r) \\times r} & \\mathbf{0}_{(m-r) \\times (n-r)}\n",
    "        \\end{matrix}\n",
    "    \\right]}_{\\mathbf{Σ}}\n",
    "    \\underbrace{\\left[\n",
    "    \\begin{matrix}\n",
    "        \\mathbf{V}_1^T \\\\\n",
    "        \\mathbf{V}_2^T\n",
    "    \\end{matrix}\n",
    "    \\right]}_{\\mathbf{V}^T}\n",
    "\\end{align*}$$\n",
    "\n",
    "$\\mathbf{Σ_1} = diag(\\sigma_1,\\dots\\,\\sigma_r)$且有$\\sigma_r > 0$，$\\mathbf{U}_1∈\\mathbb{R}^{m \\times r}$是对应于r个非零奇异值的左奇异矩阵，$\\mathbf{U}_2∈\\mathbb{R}^{m \\times (m-r)}$是对应于0奇异值的左奇异矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二种形式：迷你型\n",
    "\n",
    "$$\\begin{align*}\n",
    "   A&=\\mathbf{UΣV^T} \\\\\n",
    "    &=[\\underbrace{\\mathbf{U_1}}_\\text{r}\\underbrace{\\mathbf{U_2}}_\\text{m-r}]\n",
    "    \\left[\n",
    "        \\begin{matrix}\n",
    "            \\mathbf{Σ_1} & \\mathbf{0} \\\\\n",
    "            \\mathbf{0} & \\mathbf{0}\n",
    "        \\end{matrix}\n",
    "    \\right]\n",
    "    \\left[\n",
    "    \\begin{matrix}\n",
    "        \\mathbf{V}_1^T \\\\\n",
    "        \\mathbf{V}_2^T\n",
    "    \\end{matrix}\n",
    "    \\right] \\\\\n",
    "    &=\\mathbf{U_1Σ_1V_1^T}\n",
    "\\end{align*}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三种形式：外积型\n",
    "\n",
    "$$\\begin{align*}\n",
    "    \\mathbf{A}&=\\mathbf{UΣV^T} \\\\\n",
    "     &=\\sum_{i=1}^r\\sigma_i\\mathbf{u_iv_i^T}\n",
    "  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD和特征值分解的关系\n",
    "\n",
    "* 已知$\\mathbf{A}=\\mathbf{UΣV^T}$，可得\n",
    "\n",
    "$$\\mathbf{AA^T} = \\mathbf{UΣΣ^TU^T} = \\mathbf{U\\Lambda_LU^T}$$\n",
    "\n",
    "$$\\mathbf{\\Lambda_L} = \n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "    \\mathbf{Σ_1^2} & \\mathbf{0} \\\\\n",
    "    \\mathbf{0} & \\mathbf{0}\n",
    "\\end{matrix}\n",
    "\\right]$$\n",
    "\n",
    "* 结论：$\\mathbf{U}$是$\\mathbf{AA^T}$的特征向量，$\\sigma_1^2,\\dots,\\sigma_r^2,0,\\dots,0$特征值，即\n",
    "\n",
    "$$\\sigma_k = \\sqrt{λ_k(\\mathbf{AA^T})} = \\sqrt{λ_k(\\mathbf{A^TA})}$$\n",
    "\n",
    "* 思考正定矩阵的奇异值分解？特征值就是奇异值，可见特征值是奇异值的一种特殊形式\n",
    "\n",
    "* 同理：$\\mathbf{V}$是$\\mathbf{A^TA}$的特征向量，$\\sigma_1^2,\\dots,\\sigma_r^2,0,\\dots,0$特征值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明Σ1是正定对角阵\n",
    "# A^TA = VΣ^TU^TUΣV^T = VΣ^TΣV^T = VΛL^TV^T，继而有V是A^TA的特征向量，特征值依然是σ1^2,…,σr^2,0,…,0\n",
    "# 对于任意矩阵A，A的奇异值是AA^T或者是A^TA的特征值的开方，而对于正定矩阵A，则A的奇异值是大于0的，不存在为0的奇异值，固有奇异值就是它的特征值\n",
    "# 说明这边的λk是AA^T和A^TA的特征值，也就是σ21,…,σ2r,0,…,0，开方后，为σ1,σ2,...,0,...,0，除去为0的奇异值，那A的奇异值也就是它的特征值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD和子空间的关系\n",
    "\n",
    "* 列空间：$C(\\mathbf{A})=\\{\\mathbf{y|y=Ax}\\}$\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathbf{Ax}&=[\\mathbf{U_1U_2}]\n",
    "    \\left[\n",
    "    \\begin{matrix}\n",
    "        \\mathbf{Σ}_1 & \\mathbf{0} \\\\\n",
    "        \\mathbf{0} & \\mathbf{0}\n",
    "    \\end{matrix}\n",
    "    \\right]\n",
    "    \\left[\n",
    "    \\begin{matrix}\n",
    "        \\mathbf{V_1}^T \\\\\n",
    "        \\mathbf{V_2}^T\n",
    "    \\end{matrix}\n",
    "    \\right]\\mathbf{x} \\\\\n",
    "    &=[\\mathbf{U_1U_2}]\n",
    "    \\left[\n",
    "    \\begin{matrix}\n",
    "        \\mathbf{Σ}_1 & \\mathbf{0} \\\\\n",
    "        \\mathbf{0} & \\mathbf{0}\n",
    "    \\end{matrix}\n",
    "    \\right]\n",
    "    \\left[\n",
    "    \\begin{matrix}\n",
    "        \\mathbf{c_1} \\\\\n",
    "        \\mathbf{c_2}\n",
    "    \\end{matrix}\n",
    "    \\right] \\\\\n",
    "    &=[\\mathbf{U_1U_2}]\n",
    "    \\left[\n",
    "    \\begin{matrix}\n",
    "        \\mathbf{Σ_1c_1} \\\\\n",
    "        \\mathbf{0}\n",
    "    \\end{matrix}\n",
    "    \\right] \\\\\n",
    "    &=\\mathbf{U_1}(\\mathbf{Σ_1c_1})\n",
    "\\end{align*}$$\n",
    "\n",
    "* 令$\\mathbf{Σ_1c_1} = \\mathbf{y}$，可看出$\\mathbf{y}$与$\\mathbf{U_1}$的列向量间的线性组合，继而有$C(\\mathbf{A})=C(\\mathbf{U_1})$\n",
    "\n",
    "    * 我们有$\\mathbf{U}_1 = [\\mathbf{u}_1 \\mathbf{u}_2 \\dots \\mathbf{u}_r]$，$\\mathbf{y} = \n",
    "     \\begin{bmatrix}\n",
    "         y_1 \\\\\n",
    "         y_2 \\\\\n",
    "         \\vdots \\\\\n",
    "         y_r\n",
    "     \\end{bmatrix}$，因$\\mathbf{Σ_1c_1} = \\mathbf{y}$，$\\mathbf{y}$的所有元素都是来自于$\\mathbf{Σ_1c_1}$，而$\\mathbf{Σ}_1$中的所有元素都不为0，再因矩阵$\\mathbf{A}$是正交矩阵，正交矩阵的各个列向量一定线性无关，固有$[\\mathbf{u}_1 \\mathbf{u}_2 \\dots \\mathbf{u}_r]$线性无关，我们有$\\mathbf{A}=[\\mathbf{a}_1 \\dots \\mathbf{a}_r \\mathbf{a}_{r+1} \\dots \\mathbf{a}_m]$，$\\mathbf{x} = [x_1 \\dots x_r x_{r+1} \\dots x_m]$，$\\mathbf{Ax} = \\mathbf{a}_1x_1 + \\mathbf{a}_2x_1 + \\dots + \\mathbf{a}_rx_r + \\mathbf{a}_{r+1}x_{r+1} + \\dots + \\mathbf{a}_mx_m$，因从奇异值分解可以看出，矩阵$\\mathbf{A}$前$r$列为线性无关列，故$Rank(A)=r$，进而有$C(\\mathbf{A})=C(\\mathbf{U_1})$\n",
    "     \n",
    "\n",
    "* 零空间：$N(\\mathbf{A}) = \\{\\mathbf{x≠0}\\hspace{0.1cm}|\\hspace{0.1cm}\\mathbf{Ax=0}\\}$\n",
    "\n",
    "\n",
    "* 设$\\mathbf{x=V_2c}$\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathbf{Ax}&=[\\mathbf{U}_1\\mathbf{U}_2]\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "    \\mathbf{Σ}_1 & \\mathbf{0} \\\\\n",
    "    \\mathbf{0}  & \\mathbf{0} \n",
    "\\end{matrix}\n",
    "\\right]\n",
    "\\left[\n",
    "\\begin{matrix}\n",
    "    \\mathbf{0} \\\\\n",
    "    \\mathbf{c} \n",
    "\\end{matrix}\n",
    "\\right] \\\\\n",
    "        &=\\mathbf{0}\n",
    "\\end{align*}$$\n",
    "\n",
    "* $\\mathbf{V}_2$是$N(\\mathbf{A})$的正交基\n",
    "\n",
    "    * 因令$\\mathbf{x=V_2c}$，能够使得$\\mathbf{Ax=0}$，故$\\mathbf{x=V_2c}$是零空间$N(A)={\\mathbf{Ax=0}}$的解，$\\mathbf{x}$可以写成\n",
    "    $\\begin{bmatrix}\n",
    "        \\mathbf{0} \\\\\n",
    "        \\mathbf{V}_2\\mathbf{c}\n",
    "     \\end{bmatrix}$，进而有$\\mathbf{Ax} = \\mathbf{a}_1\\cdot0 + \\dots +  \\mathbf{a}_r\\cdot0 + \\mathbf{a}_{r+1}\\cdot\\mathbf{v}_{r+1}c_{r+1} + \\dots + \\mathbf{a}_{m}\\cdot\\mathbf{v}_{m}c_{m} = \\mathbf{0}$，因向量$\\mathbf{x≠0}$，故$\\mathbf{V}_2\\mathbf{c}≠\\mathbf{0}$，又要求等式为$\\mathbf{0}$，所以只能$\\mathbf{a}_{r+1}\\cdot\\mathbf{v}_{r+1} \\dots \\mathbf{a}_{m}\\cdot\\mathbf{v}_{m} = 0$，固有$\\mathbf{V}_2$是$N(\\mathbf{A})$的正交基\n",
    "\n",
    "* 思考：$\\mathbf{Ax=b}$的解?\n",
    "    \n",
    "    令$\\mathbf{x=p+z=p+V_2c}$，有$\\mathbf{A(p+z)}=\\mathbf{Ap+0}=\\mathbf{Ap}$，因$\\mathbf{p}$是其的一个通解，即有$\\mathbf{Ap=b}$，继而得$\\mathbf{A(p+z)=b}$，得$\\mathbf{p+z}$是$\\mathbf{Ax=b}$的解，解的组成为一个通解$\\mathbf{p}$来自列空间$C(\\mathbf{A})$，一个特解$\\mathbf{z}$来自零空间$N(\\mathbf{A})$，也就是$\\mathbf{Ax=b}$和$\\mathbf{Ax=0}$的和解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ax=b的解，为一通解p来自列空间，和一特解z来自零空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列空间C(U1)等于列空间C(A)\n",
    "# V2是零空间N(A)的正交基\n",
    "# U1+U2构成子空间R^n，V1+V2构成子空间R^m\n",
    "# 并且有正交和单位为1的关系：U1.U2=0, U1.U1=1 U2.U2=1 和 V1.V2=0, V1.V1=1 V2.V2=1\n",
    "# U = [U1 U2] V = [V1 V2]\n",
    "# 利用这种方法可以很容易求得方程组的解，一个通解p和一个特解z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD几何解释\n",
    "\n",
    "由$\\mathbf{A=UΣV^T}$，两边同时乘以$\\mathbf{V}$，得到$\\mathbf{AV}=\\mathbf{UΣ}$，因$\\mathbf{V}=[\\mathbf{V}_1 \\mathbf{V}_2]$，继而得到$\\mathbf{AV_1}=\\sigma_1\\mathbf{U}_1$，$\\mathbf{AV_2}=\\sigma_2\\mathbf{U}_2$，也就是说特征向量$\\mathbf{V}_1$和$\\mathbf{V}_2$在矩阵$\\mathbf{A}$的作用下，分别变换成了$\\sigma_1$倍的$\\mathbf{U}_1$和$\\sigma_2$倍的$\\mathbf{U}_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：\n",
    "# V1V2两正交矩阵在矩阵A的作用下发生了偏转，并且分别在U1和U2方向伸缩了σ1和σ2倍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 矩阵其它重要知识"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "投影\n",
    "\n",
    "投影角度看$\\mathbf{Ax=b}$\n",
    "\n",
    "因$\\mathbf{b}∉C(\\mathbf{A})$，所以该解因包含列空间的解和零空间的解。设矩阵$\\mathbf{A}=[\\mathbf{a}_1 \\mathbf{a}_2]$，$\\mathbf{a}_1$和$\\mathbf{a}_2$两列向量都分布在同一超平面上，而向量$\\mathbf{b}$为超平面外的一向量，或者说$\\mathbf{a}_1$和$\\mathbf{a}_2$列向量组成的列空间$\\mathbf{C(A)}$外的向量，我们要在这个组成的超平面上找到向量$\\mathbf{b}$的近似解$\\mathbf{b'}$，继而有$\\mathbf{b'}=\\mathbf{A \\hat{x}}$，很明显要要求这个近似解最大并且要满足是$\\mathbf{Ax=b}$的解，就必须是投影到超平面上的方向，也就是垂直于超平面，继而有$\\mathbf{a_1e}=0$，$\\mathbf{a_2e}=0$ $\\Rightarrow$ $\\mathbf{A^Te}=\\mathbf{A^T(b-b')=0}$ $\\Rightarrow$ 其解形式为一个特解来自$N(\\mathbf{A})$和一个通解来自$C(\\mathbf{A})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "行列式\n",
    "\n",
    "* $det(\\mathbf{AB})=det(\\mathbf{A})det(\\mathbf{B})$\n",
    "* $det(\\mathbf{A})=det(\\mathbf{A^T})$\n",
    "* $det(α\\mathbf{A})=det(α^m\\mathbf{A})$\n",
    "* $det(\\mathbf{A})≠0 \\Longleftrightarrow \\mathbf{A}可逆$\n",
    "* $\\mathbf{A}可逆，则det(\\mathbf{A}^{-1})=\\frac{1}{det(\\mathbf{A})}$\n",
    "* 如果$\\mathbf{B}$可逆，则$det(\\mathbf{B}^{-1}AB)=det(\\mathbf{A})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：矩阵A的逆，不等于1/A\n",
    "# 二阶行列式几何意义：为两向量围成的平行四边形的面积 S=ad-bc\n",
    "# 三阶行列式几何意义：为三向量围成的平行六面体的体积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "广义逆(伪逆)\n",
    "\n",
    "* $\\mathbf{Ax=b}$\n",
    "* $\\mathbf{A^{\\dagger}}=\\mathbf{VΣ^{\\dagger}U^\\mathsf{T}}$\n",
    "* 对于$\\mathbf{A}∈\\mathbb{R}^{m \\times n}$，如果$m<n$，则$\\mathbf{x=A^{\\dagger}b}$是最小二范数解\n",
    "* 如果$m>n$，$\\mathbf{x=A^{\\dagger}b}$使得$\\|\\mathbf{Ax-b}\\|_2$最小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trace(迹) - 矩阵对角元之和\n",
    "\n",
    "* $\\mathsf{Tr}(\\mathsf{A})$ = $\\sum_i\\mathsf{A}(i,i)$\n",
    "* $\\mathsf{Tr}(\\mathsf{AB})$ = $\\mathsf{Tr}(\\mathsf{BA})$\n",
    "* $\\|\\mathsf{A}\\|_F^2$ = $\\mathsf{Tr(AA^T)}$\n",
    "* Link奇异值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推导：∥𝖠∥2F = ∥UΣVT∥2F = ∥Σ∥2F = σ1^2+...+σr^2\n",
    "# 因U和V是正交矩阵不影响范数，继而有∥UΣVT∥2F = ∥Σ∥2F\n",
    "# 广义逆：说的是对于任意矩阵，存在近似矩阵的逆，如行列式为0的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：矩阵的F范数，相当于向量的二范数，在求矩阵的大小\n",
    "# 是为了表示不能用向量范数来诱导的矩阵表示大小的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实际运用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "低秩矩阵近似\n",
    "\n",
    "* 给定矩阵$\\mathsf{A}∈\\mathbb{R}^{m \\times n}$，其秩为r，需找一个矩阵$\\mathsf{B}∈\\mathbb{R}^{m \\times n}$，其秩为$k < r$，使其能够最接近$\\mathsf{A}$\n",
    "\n",
    "* 若$\\mathsf{A}=\\mathsf{UΣV^T}=\\sum_{i=1}^pu_iv_i^T$，定义\n",
    "\n",
    "$$\\mathsf{B}=\\mathsf{UΣV^T}=\\sum_{i=1}^ku_iv_i^T$$\n",
    "\n",
    "* 应用：PCA，维数减少，数据压缩等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于任意A矩阵，都可以进行奇异值分解，分解后取主成分的矩阵B能够以最大奇异值接近矩阵A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：矩阵的近似，很大程度上式应用在图像压缩和数据降维领域，压缩和降维后的数据仍能够保证数据的可读性和较好的特征属性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "低秩矩阵近似应用 - 图像压缩\n",
    "\n",
    "* 给定一副图像，$256 \\times 512 = 2^{17}$矩阵\n",
    "* $\\mathsf{CT\\hspace{0.1cm}MR}$需要图像压缩，希望尽可能无损\n",
    "* 傅里叶变换(jpeg)，小波(jpeg2000)\n",
    "* 考虑用低秩矩阵近似方式：存储$\\{\\sigma_i,\\mathsf{u_i,v_i}\\}_{i=1}^k$，$k=1$时，压缩比大致是$256\\times512/(256+512)=170$\n",
    "* 当$k=1,10,80$时，会有不同的显示效果，在80时，几乎与原图无差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本来每个像素需要存储一个颜色的数值，也就是共256x512个值，是每个矩阵的元素值\n",
    "# 而采用PCA主成分之后，若k=1，整个矩阵只要存储一个主成分信息1+(256+512)的特征向量信息\n",
    "# 若k=10，则需要存储10*(1+256+512)的信息\n",
    "# 图像可以形象化地理解为矩阵，但是信息存储确是以文件的形式，存储内容也会不同，如本来存储256x512个颜色值，而PCA后，存储的是k(1+256+512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 说明：这边的K是表示取主成分的个数，k=1是取最大主成分\n",
    "# 一个图像像素的大小反应了矩阵的大小，如m*n个像素的图像，那其图像的大小为m*n*3*8bit，而采用SVD进行图像压缩，我们可以选择压缩的比例，比如选择\n",
    "# 奇异值的个数为k=10，则压缩后的图像大小为k(m+n+1)*3*8bit，以此可以算出压缩比为(m*n)/k(m+n+1)\n",
    "# 解释原理：原图像是每个像素点存储一个RGB的颜色码，而采用SVD压缩，比如这边的k取10，也就是我们将颜色大致分为10个主成分的颜色，其后每个像素点\n",
    "# 只要记录属于哪个分类成分和对应的特征向量u,v即可，那总共需要存储k(m+n+1)个元素"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
